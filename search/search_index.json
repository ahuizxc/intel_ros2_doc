{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Intel Ros2 Project Tutorial Overview Intel Ros2 Project contains several ROS2 packages in object classification, detection, localization and tracking and SLAM. Package Lists ros2_intel_realsense ros2_intel_realsense for using Intel RealSense cameras (D400 series) with ROS2. ros2_intel_movidius_ncs ros2_intel_movidius_ncs is a ROS2 wrapper for NC API of NCSDK, providing the following features: A ROS2 service for object classification and detection of a static image file. A ROS2 publisher for object classification and detection of a video stream from a RGB camera. Demo applications to show the capabilities of ROS2 service and publisher. Support multiple CNN models of Caffe and Tensorflow. ros2_object_analytics ros2_object_analytics is a ROS2 wrapper for realtime object detection, localization and tracking. These packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM. ros2_object_map ros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses ros2_object_analytics for object detection. ros2_moving_object ros2_moving_object is addressing moving objects based on messages generated by Object Analytics ros2_object_analytics. ros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding motion information, i.e., the velocity information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance. Now this project has been integrated into project ros2_object_analytics. ros2_openvino_toolkit The OpenVINO\u2122 toolkit quickly deploys applications and solutions that emulate human vision. Based on Convolutional Neural Networks (CNN), the Toolkit extends computer vision (CV) workloads across Intel\u00ae hardware, maximizing performance. This project is a ROS2 wrapper for CV API of OpenVINO\u2122, providing the following features: Support CPU and GPU platforms Support standard USB camera and Intel\u00ae RealSense\u2122 camera Support Video or Image file as detection source Face detection Emotion recognition Age and gender recognition Head pose recognition Object detection Demo application to show above detection and recognitions License Copyright 2018 Intel Corporation Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this project except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. * Other names and brands may be claimed as the property of others Any security issue should be reported using process at https://01.org/security","title":"Home"},{"location":"#intel-ros2-project-tutorial","text":"","title":"Intel Ros2 Project Tutorial"},{"location":"#overview","text":"Intel Ros2 Project contains several ROS2 packages in object classification, detection, localization and tracking and SLAM.","title":"Overview"},{"location":"#package-lists","text":"","title":"Package Lists"},{"location":"#ros2_intel_realsense","text":"ros2_intel_realsense for using Intel RealSense cameras (D400 series) with ROS2.","title":"ros2_intel_realsense"},{"location":"#ros2_intel_movidius_ncs","text":"ros2_intel_movidius_ncs is a ROS2 wrapper for NC API of NCSDK, providing the following features: A ROS2 service for object classification and detection of a static image file. A ROS2 publisher for object classification and detection of a video stream from a RGB camera. Demo applications to show the capabilities of ROS2 service and publisher. Support multiple CNN models of Caffe and Tensorflow.","title":"ros2_intel_movidius_ncs"},{"location":"#ros2_object_analytics","text":"ros2_object_analytics is a ROS2 wrapper for realtime object detection, localization and tracking. These packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM.","title":"ros2_object_analytics"},{"location":"#ros2_object_map","text":"ros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses ros2_object_analytics for object detection.","title":"ros2_object_map"},{"location":"#ros2_moving_object","text":"ros2_moving_object is addressing moving objects based on messages generated by Object Analytics ros2_object_analytics. ros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding motion information, i.e., the velocity information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance.","title":"ros2_moving_object"},{"location":"#now-this-project-has-been-integrated-into-project-ros2_object_analytics","text":"","title":"Now this project has been integrated into project ros2_object_analytics."},{"location":"#ros2_openvino_toolkit","text":"The OpenVINO\u2122 toolkit quickly deploys applications and solutions that emulate human vision. Based on Convolutional Neural Networks (CNN), the Toolkit extends computer vision (CV) workloads across Intel\u00ae hardware, maximizing performance. This project is a ROS2 wrapper for CV API of OpenVINO\u2122, providing the following features: Support CPU and GPU platforms Support standard USB camera and Intel\u00ae RealSense\u2122 camera Support Video or Image file as detection source Face detection Emotion recognition Age and gender recognition Head pose recognition Object detection Demo application to show above detection and recognitions","title":"ros2_openvino_toolkit"},{"location":"#license","text":"Copyright 2018 Intel Corporation Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this project except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. * Other names and brands may be claimed as the property of others","title":"License"},{"location":"#any-security-issue-should-be-reported-using-process-at-https01orgsecurity","text":"","title":"Any security issue should be reported using process at https://01.org/security"},{"location":"acknowledegment/","text":"Acknowledegment Intel ROS2 Project was contributed by Intel OTC Robotics PRC: Yang, Harold [harold.yang@intel.com] Gao, Ethan [ethan.gao@intel.com] Huang, Xiaojun [xiaojun.huang@intel.com] Li, Chao [chao1.li@intel.com] Liu, Sharron [sharron.liu@intel.com] Liu, Weizhi [wei.zhi.liu@intel.com] Shen, Cathy [cathy.shen@intel.com] Yan, Yu [yu.yan@intel.com] Ye, Chris [chris.ye@intel.com] Guo, Tonny [tony.guo@intel.com] Liu, Shenghui [shenghui.liu@intel.com]","title":"Acknowledgement"},{"location":"acknowledegment/#acknowledegment","text":"Intel ROS2 Project was contributed by Intel OTC Robotics PRC: Yang, Harold [harold.yang@intel.com] Gao, Ethan [ethan.gao@intel.com] Huang, Xiaojun [xiaojun.huang@intel.com] Li, Chao [chao1.li@intel.com] Liu, Sharron [sharron.liu@intel.com] Liu, Weizhi [wei.zhi.liu@intel.com] Shen, Cathy [cathy.shen@intel.com] Yan, Yu [yu.yan@intel.com] Ye, Chris [chris.ye@intel.com] Guo, Tonny [tony.guo@intel.com] Liu, Shenghui [shenghui.liu@intel.com]","title":"Acknowledegment"},{"location":"installation/","text":"Installation Instructions Install the Intel\u00ae RealSense\u2122 SDK 2.0 Install tag v2.16.5_ros2 Intel\u00ae RealSense\u2122 SDK 2.0 and follow the instructions under Linux Installation . Note: Use git checkout v2.16.5_ros2 to switch to the correct branch. Install ROS1 Kinetic(Optional) Ubuntu install of ROS Kinetic( ros-kinetic-desktop-full ) Install ROS2 Bouncy Ubuntu install of ROS Crystal Source the environment cd ~/ros2_ws source install/local_setup.bash Install ROS2 Base Packages 1. Install ros2 vision_opencv cd ~/ros2_ws source install/local_setup.bash # Creating a new ROS2 workspace 'ros2_overlay_ws' instead of using 'ros2_ws' is recommended mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/ros-perception/vision_opencv.git git checkout ros2 cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install source ~/ros2_overlay_ws/install/local_setup.bash 2. Install ros2_object_msgs cd ~/ros2_overlay_ws/src # Clone the ros2_object_msgs repository and build use colcon git clone https://github.com/intel/ros2_object_msgs.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select object_msgs source ~/ros2_overlay_ws/install/local_setup.bash 3. Install ros2_message_filters cd /usr/lib/x86_64-linux-gnu # Create a symbol link from libboost_python-py35.so to libboost_python3.so sudo ln -s libboost_python-py35.so libboost_python3.so cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_message_filters.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select message_filters source ~/ros2_overlay_ws/install/local_setup.bash Install Intel ROS2 Packages 1. Install ros2_intel_realsense # Goto the new ROS workspace step 4 created before cd ~/ros2_overlay_ws/src # Clone the latest Intel\u00ae RealSense\u2122 ROS2 repository and build use colcon git clone https://github.com/intel/ros2_intel_realsense.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select realsense_camera_msgs realsense_ros2_camera source ~/ros2_overlay_ws/install/local_setup.bash # Create a symbol link from libusb.a to libusb-1.0.a, otherwise \"libusb.a\" is probably not to be found by librealsense sudo ln -s /usr/lib/x86_64-linux-gnu/libusb-1.0.a /usr/lib/libusb.a 2. Install ros2_intel_movidius_ncs # Install [NCSDK 1.x](https://github.com/movidius/ncsdk) and [NCAPPZOO](https://github.com/movidius/ncappzoo) at first # create workspace to install libraries ros2_intel_moidius_ncs relies on mkdir -p ~/workspace/libraries cd ~/workspace/libraries # install ncsdk and ncappzoo git clone https://github.com/movidius/ncsdk.git git clone https://github.com/movidius/ncappzoo.git cd ~/workspace/libraries/ncsdk sudo make install export PYTHONPATH=\"${PYTHONPATH}:/opt/movidius/caffe/python\" # Download and compile the object detection model cd ~/workspace/libraries/ncappzoo/caffe/ sudo make cd ~/workspace/libraries/ncappzoo/tensorflow/ sudo make # NCSDK should be installed in /opt/movidius by default. Create a symbol link in /opt/movidius to NCAPPZOO sudo ln -s ~/workspace/libraries/ncappzoo /opt/movidius/ncappzoo # Install ros2_intel_movidius_ncs cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_intel_movidius_ncs.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select movidius_ncs_example movidius_ncs_image movidius_ncs_launch movidius_ncs_lib movidius_ncs_stream source ~/ros2_overlay_ws/install/local_setup.bash 3. Install ros2_object_analytics # Install pcl_conversions package at first cd ~/ros2_ws/src git clone https://github.com/ros2/pcl_conversions.git cd pcl_conversions git checkout bouncy cd ~/ros2_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select pcl_conversions # Install ros2_object_analytics cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_object_analytics.git cd .. source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select object_analytics_launch object_analytics_node object_analytics_msgs object_analytics_rviz source ~/ros2_overlay_ws/install/local.setup.bash 4. Install ros2_object_map cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_object_map.git cd .. source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select object_map object_map_msgs source ~/ros2_overlay_ws/install/local.setup.bash 5. Install ros2_openvino_toolkit Hardware and system requirements: An x86_64 computer running Ubuntu. Below processors are supported: 6th-8th Generation Intel\u00ae Core\u2122 Intel\u00ae Xeon\u00ae v5 family Intel\u00ae Xeon\u00ae v6 family ROS2 Crystal RGB Camera, e.g. RealSense D400 Series or standard USB camera or Video/Image File Graphics are required only if you use a GPU. The official system requirements for GPU are: 6th to 8th generation Intel\u00ae Core\u2122 processors with Iris\u00ae Pro graphics and Intel\u00ae HD Graphics 6th to 8th generation Intel\u00ae Xeon\u00ae processors with Iris Pro graphics and Intel HD Graphics (excluding the e5 product family, which does not have graphics) Intel\u00ae Pentium\u00ae processors N4200/5, N3350/5, N3450/5 with Intel HD Graphics Use one of the following methods to determine the GPU on your hardware: [lspci] command: GPU info may lie in the [VGA compatible controller] line. Ubuntu system: Menu [System Settings] --> [Details] may help you find the graphics information. Openvino: Download the install package, install_GUI.sh inside will check the GPU information before installation. Note :We provide two ways to install the OpenVINO\u2122 toolkit: Install from Binary version(Only support ubuntu 16.04) Environment Setup: Install OpenVINO\u2122 Toolkit ( guide ) Note : Please use root privileges to run the installer when installing the core components. Install OpenCL Driver for GPU cd /opt/intel/computer_vision_sdk/install_dependencies sudo ./install_NEO_OCL_driver.sh Other Dependencies # numpy pip3 install numpy # libboost sudo apt-get install -y --no-install-recommends libboost-all-dev cd /usr/lib/x86_64-linux-gnu sudo ln -s libboost_python-py35.so libboost_python3.so Building and Installation: Note :You can also choose to follow the steps below to build the environment step by step. Build sample code under openvino toolkit # root is required instead of sudo source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd /opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/ mkdir build cd build cmake .. make set ENV CPU_EXTENSION_LIB and GFLAGS_LIB export CPU_EXTENSION_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libcpu_extension.so export GFLAGS_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libgflags_nothreads.a Install ROS2_OpenVINO package mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_openvino_toolkit Build package source ~/ros2_ws/install/local_setup.bash source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd ~/ros2_overlay_ws colcon build --symlink-install source ./install/local_setup.bash sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/ros2_overlay_ws/src/ros2_openvino_toolkit /opt/openvino_toolkit/ros2_openvino_toolkit Build sample code under openvino toolkit # root is required instead of sudo source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd /opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/ mkdir build cd build cmake .. make set ENV CPU_EXTENSION_LIB and GFLAGS_LIB export CPU_EXTENSION_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libcpu_extension.so- [OpenVINO\u2122 Toolkit](https://software.intel.com/en-us/openvino-toolkit) export GFLAGS_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libgflags_nothreads.a Install ROS2_OpenVINO packages mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_openvino_toolkit Build package source ~/ros2_ws/install/local_setup.bash source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd ~/ros2_overlay_ws colcon build --symlink-install source ./install/local_setup.bash sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/ros2_overlay_ws/src/ros2_openvino_toolkit /opt/openvino_toolkit/ros2_openvino_toolkit Install from Source code(Both support ubuntu 16.04 and 18.04) Environment Setup Note :You can choose to build the environment using ./environment_setup.sh script in the script subfolder. ./environment_setup.sh hostname password Note :You can also choose to follow the steps below to build the environment step by step. Install OpenVINO\u2122 Toolkit Open Source Install OpenCV 3.3 or later ( guide ) [compiler] sudo apt-get install build-essential [required] sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev [optional] sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev cd ~/code git clone https://github.com/opencv/opencv.git git clone https://github.com/opencv/opencv_contrib.git cd opencv && git checkout 3.3.1 && cd .. cd opencv_contrib && git checkout 3.3.1 && cd .. cd opencv mkdir build && cd build cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local -D OPENCV_EXTRA_MODULES_PATH=/home/<hostname>/code/opencv_contrib/modules/ .. make -j8 sudo make install Additional steps are required on ubuntu 18.04 sudo add-apt-repository \"deb http://security.ubuntu.com/ubuntu xenial-security main\" sudo apt update sudo apt install libjasper1 libjasper-dev Install OpenCL Driver for GPU( guide ) cd ~/Downloads wget http://registrationcenter-download.intel.com/akdlm/irc_nas/11396/SRB5.0_linux64.zip unzip SRB5.0_linux64.zip -d SRB5.0_linux64 cd SRB5.0_linux64 sudo apt-get install xz-utils mkdir intel-opencl tar -C intel-opencl -Jxf intel-opencl-r5.0-63503.x86_64.tar.xz tar -C intel-opencl -Jxf intel-opencl-devel-r5.0-63503.x86_64.tar.xz tar -C intel-opencl -Jxf intel-opencl-cpu-r5.0-63503.x86_64.tar.xz sudo cp -R intel-opencl/* / sudo ldconfig Note :On Ubuntu 18.04,replace libpng12-dev with libpng-dev in the install_dependencies.sh file. Install Deep Learning Deployment Toolkit ( guide ) mkdir ~/code && cd ~/code git clone https://github.com/opencv/dldt.git cd dldt/inference-engine/ git checkout 2018_R3 ./install_dependencies.sh mkdir build && cd build cmake -DCMAKE_BUILD_TYPE=Release .. make -j8 sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/code/dldt /opt/openvino_toolkit/dldt Install Open Model Zoo ( guide ) cd ~/code git clone https://github.com/opencv/open_model_zoo.git cd open_model_zoo/demos/ git checkout e238a1ac6bfacf133be223dd9debade7bfcf7dc5 mkdir build && cd build cmake -DCMAKE_BUILD_TYPE=Release /opt/openvino_toolkit/dldt/inference-engine make -j8 sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/code/open_model_zoo /opt/openvino_toolkit/open_model_zoo Other Dependencies # numpy pip3 install numpy Ubuntu 16.04 # libboost sudo apt-get install -y --no-install-recommends libboost-all-dev cd /usr/lib/x86_64-linux-gnu sudo ln -s libboost_python-py35.so libboost_python3.so Ubuntu 18.04 #libboost sudo apt-get install -y --no-install-recommends libboost-all-dev sudo apt install libboost-python1.62.0 Building and Installation set ENV InferenceEngine_DIR, CPU_EXTENSION_LIB and GFLAGS_LIB export InferenceEngine_DIR=/opt/openvino_toolkit/dldt/inference-engine/build/ export CPU_EXTENSION_LIB=/opt/openvino_toolkit/dldt/inference-engine/bin/intel64/Release/lib/libcpu_extension.so export GFLAGS_LIB=/opt/openvino_toolkit/dldt/inference-engine/bin/intel64/Release/lib/libgflags_nothreads.a Install ROS2_OpenVINO packages mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_openvino_toolkit Build package source ~/ros2_ws/install/local_setup.bash cd ~/ros2_overlay_ws colcon build --symlink-install source ./install/local_setup.bash sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/ros2_overlay_ws/src/ros2_openvino_toolkit /opt/openvino_toolkit/ros2_openvino_toolkit Note :In pipeline_people_oss.yaml and pipeline_object_oss.yaml ,options for inputs parameter: StandardCamera or RealSenseCamera. Default is StandardCamera. * run sample code with parameters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_people_oss.yaml run object detection sample code with paramters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_object_oss.yaml","title":"Installation"},{"location":"installation/#installation-instructions","text":"","title":"Installation Instructions"},{"location":"installation/#install-the-intel-realsensetm-sdk-20","text":"Install tag v2.16.5_ros2 Intel\u00ae RealSense\u2122 SDK 2.0 and follow the instructions under Linux Installation . Note: Use git checkout v2.16.5_ros2 to switch to the correct branch.","title":"Install the Intel\u00ae RealSense\u2122 SDK 2.0"},{"location":"installation/#install-ros1-kineticoptional","text":"Ubuntu install of ROS Kinetic( ros-kinetic-desktop-full )","title":"Install ROS1 Kinetic(Optional)"},{"location":"installation/#install-ros2-bouncy","text":"Ubuntu install of ROS Crystal Source the environment cd ~/ros2_ws source install/local_setup.bash","title":"Install ROS2 Bouncy"},{"location":"installation/#install-ros2-base-packages","text":"","title":"Install ROS2 Base Packages"},{"location":"installation/#1-install-ros2-vision_opencv","text":"cd ~/ros2_ws source install/local_setup.bash # Creating a new ROS2 workspace 'ros2_overlay_ws' instead of using 'ros2_ws' is recommended mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/ros-perception/vision_opencv.git git checkout ros2 cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install source ~/ros2_overlay_ws/install/local_setup.bash","title":"1. Install ros2 vision_opencv"},{"location":"installation/#2-install-ros2_object_msgs","text":"cd ~/ros2_overlay_ws/src # Clone the ros2_object_msgs repository and build use colcon git clone https://github.com/intel/ros2_object_msgs.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select object_msgs source ~/ros2_overlay_ws/install/local_setup.bash","title":"2. Install ros2_object_msgs"},{"location":"installation/#3-install-ros2_message_filters","text":"cd /usr/lib/x86_64-linux-gnu # Create a symbol link from libboost_python-py35.so to libboost_python3.so sudo ln -s libboost_python-py35.so libboost_python3.so cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_message_filters.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select message_filters source ~/ros2_overlay_ws/install/local_setup.bash","title":"3. Install ros2_message_filters"},{"location":"installation/#install-intel-ros2-packages","text":"","title":"Install Intel ROS2 Packages"},{"location":"installation/#1-install-ros2_intel_realsense","text":"# Goto the new ROS workspace step 4 created before cd ~/ros2_overlay_ws/src # Clone the latest Intel\u00ae RealSense\u2122 ROS2 repository and build use colcon git clone https://github.com/intel/ros2_intel_realsense.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select realsense_camera_msgs realsense_ros2_camera source ~/ros2_overlay_ws/install/local_setup.bash # Create a symbol link from libusb.a to libusb-1.0.a, otherwise \"libusb.a\" is probably not to be found by librealsense sudo ln -s /usr/lib/x86_64-linux-gnu/libusb-1.0.a /usr/lib/libusb.a","title":"1. Install ros2_intel_realsense"},{"location":"installation/#2-install-ros2_intel_movidius_ncs","text":"# Install [NCSDK 1.x](https://github.com/movidius/ncsdk) and [NCAPPZOO](https://github.com/movidius/ncappzoo) at first # create workspace to install libraries ros2_intel_moidius_ncs relies on mkdir -p ~/workspace/libraries cd ~/workspace/libraries # install ncsdk and ncappzoo git clone https://github.com/movidius/ncsdk.git git clone https://github.com/movidius/ncappzoo.git cd ~/workspace/libraries/ncsdk sudo make install export PYTHONPATH=\"${PYTHONPATH}:/opt/movidius/caffe/python\" # Download and compile the object detection model cd ~/workspace/libraries/ncappzoo/caffe/ sudo make cd ~/workspace/libraries/ncappzoo/tensorflow/ sudo make # NCSDK should be installed in /opt/movidius by default. Create a symbol link in /opt/movidius to NCAPPZOO sudo ln -s ~/workspace/libraries/ncappzoo /opt/movidius/ncappzoo # Install ros2_intel_movidius_ncs cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_intel_movidius_ncs.git cd ~/ros2_overlay_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select movidius_ncs_example movidius_ncs_image movidius_ncs_launch movidius_ncs_lib movidius_ncs_stream source ~/ros2_overlay_ws/install/local_setup.bash","title":"2. Install ros2_intel_movidius_ncs"},{"location":"installation/#3-install-ros2_object_analytics","text":"# Install pcl_conversions package at first cd ~/ros2_ws/src git clone https://github.com/ros2/pcl_conversions.git cd pcl_conversions git checkout bouncy cd ~/ros2_ws source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select pcl_conversions # Install ros2_object_analytics cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_object_analytics.git cd .. source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select object_analytics_launch object_analytics_node object_analytics_msgs object_analytics_rviz source ~/ros2_overlay_ws/install/local.setup.bash","title":"3. Install ros2_object_analytics"},{"location":"installation/#4-install-ros2_object_map","text":"cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_object_map.git cd .. source ~/ros2_ws/install/local_setup.bash colcon build --symlink-install --packages-select object_map object_map_msgs source ~/ros2_overlay_ws/install/local.setup.bash","title":"4. Install ros2_object_map"},{"location":"installation/#5-install-ros2_openvino_toolkit","text":"","title":"5. Install ros2_openvino_toolkit"},{"location":"installation/#hardware-and-system-requirements","text":"An x86_64 computer running Ubuntu. Below processors are supported: 6th-8th Generation Intel\u00ae Core\u2122 Intel\u00ae Xeon\u00ae v5 family Intel\u00ae Xeon\u00ae v6 family ROS2 Crystal RGB Camera, e.g. RealSense D400 Series or standard USB camera or Video/Image File Graphics are required only if you use a GPU. The official system requirements for GPU are: 6th to 8th generation Intel\u00ae Core\u2122 processors with Iris\u00ae Pro graphics and Intel\u00ae HD Graphics 6th to 8th generation Intel\u00ae Xeon\u00ae processors with Iris Pro graphics and Intel HD Graphics (excluding the e5 product family, which does not have graphics) Intel\u00ae Pentium\u00ae processors N4200/5, N3350/5, N3450/5 with Intel HD Graphics Use one of the following methods to determine the GPU on your hardware: [lspci] command: GPU info may lie in the [VGA compatible controller] line. Ubuntu system: Menu [System Settings] --> [Details] may help you find the graphics information. Openvino: Download the install package, install_GUI.sh inside will check the GPU information before installation. Note :We provide two ways to install the OpenVINO\u2122 toolkit:","title":"Hardware and system requirements:"},{"location":"installation/#install-from-binary-versiononly-support-ubuntu-1604","text":"","title":"Install from Binary version(Only support ubuntu 16.04)"},{"location":"installation/#environment-setup","text":"Install OpenVINO\u2122 Toolkit ( guide ) Note : Please use root privileges to run the installer when installing the core components. Install OpenCL Driver for GPU cd /opt/intel/computer_vision_sdk/install_dependencies sudo ./install_NEO_OCL_driver.sh Other Dependencies # numpy pip3 install numpy # libboost sudo apt-get install -y --no-install-recommends libboost-all-dev cd /usr/lib/x86_64-linux-gnu sudo ln -s libboost_python-py35.so libboost_python3.so","title":"Environment Setup:"},{"location":"installation/#building-and-installation","text":"Note :You can also choose to follow the steps below to build the environment step by step. Build sample code under openvino toolkit # root is required instead of sudo source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd /opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/ mkdir build cd build cmake .. make set ENV CPU_EXTENSION_LIB and GFLAGS_LIB export CPU_EXTENSION_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libcpu_extension.so export GFLAGS_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libgflags_nothreads.a Install ROS2_OpenVINO package mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_openvino_toolkit Build package source ~/ros2_ws/install/local_setup.bash source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd ~/ros2_overlay_ws colcon build --symlink-install source ./install/local_setup.bash sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/ros2_overlay_ws/src/ros2_openvino_toolkit /opt/openvino_toolkit/ros2_openvino_toolkit Build sample code under openvino toolkit # root is required instead of sudo source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd /opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/ mkdir build cd build cmake .. make set ENV CPU_EXTENSION_LIB and GFLAGS_LIB export CPU_EXTENSION_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libcpu_extension.so- [OpenVINO\u2122 Toolkit](https://software.intel.com/en-us/openvino-toolkit) export GFLAGS_LIB=/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib/libgflags_nothreads.a Install ROS2_OpenVINO packages mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_openvino_toolkit Build package source ~/ros2_ws/install/local_setup.bash source /opt/intel/computer_vision_sdk/bin/setupvars.sh cd ~/ros2_overlay_ws colcon build --symlink-install source ./install/local_setup.bash sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/ros2_overlay_ws/src/ros2_openvino_toolkit /opt/openvino_toolkit/ros2_openvino_toolkit","title":"Building and Installation:"},{"location":"installation/#install-from-source-codeboth-support-ubuntu-1604-and-1804","text":"","title":"Install from Source code(Both support ubuntu 16.04 and 18.04)"},{"location":"installation/#environment-setup_1","text":"Note :You can choose to build the environment using ./environment_setup.sh script in the script subfolder. ./environment_setup.sh hostname password Note :You can also choose to follow the steps below to build the environment step by step. Install OpenVINO\u2122 Toolkit Open Source Install OpenCV 3.3 or later ( guide ) [compiler] sudo apt-get install build-essential [required] sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev [optional] sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev cd ~/code git clone https://github.com/opencv/opencv.git git clone https://github.com/opencv/opencv_contrib.git cd opencv && git checkout 3.3.1 && cd .. cd opencv_contrib && git checkout 3.3.1 && cd .. cd opencv mkdir build && cd build cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local -D OPENCV_EXTRA_MODULES_PATH=/home/<hostname>/code/opencv_contrib/modules/ .. make -j8 sudo make install Additional steps are required on ubuntu 18.04 sudo add-apt-repository \"deb http://security.ubuntu.com/ubuntu xenial-security main\" sudo apt update sudo apt install libjasper1 libjasper-dev Install OpenCL Driver for GPU( guide ) cd ~/Downloads wget http://registrationcenter-download.intel.com/akdlm/irc_nas/11396/SRB5.0_linux64.zip unzip SRB5.0_linux64.zip -d SRB5.0_linux64 cd SRB5.0_linux64 sudo apt-get install xz-utils mkdir intel-opencl tar -C intel-opencl -Jxf intel-opencl-r5.0-63503.x86_64.tar.xz tar -C intel-opencl -Jxf intel-opencl-devel-r5.0-63503.x86_64.tar.xz tar -C intel-opencl -Jxf intel-opencl-cpu-r5.0-63503.x86_64.tar.xz sudo cp -R intel-opencl/* / sudo ldconfig Note :On Ubuntu 18.04,replace libpng12-dev with libpng-dev in the install_dependencies.sh file. Install Deep Learning Deployment Toolkit ( guide ) mkdir ~/code && cd ~/code git clone https://github.com/opencv/dldt.git cd dldt/inference-engine/ git checkout 2018_R3 ./install_dependencies.sh mkdir build && cd build cmake -DCMAKE_BUILD_TYPE=Release .. make -j8 sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/code/dldt /opt/openvino_toolkit/dldt Install Open Model Zoo ( guide ) cd ~/code git clone https://github.com/opencv/open_model_zoo.git cd open_model_zoo/demos/ git checkout e238a1ac6bfacf133be223dd9debade7bfcf7dc5 mkdir build && cd build cmake -DCMAKE_BUILD_TYPE=Release /opt/openvino_toolkit/dldt/inference-engine make -j8 sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/code/open_model_zoo /opt/openvino_toolkit/open_model_zoo Other Dependencies # numpy pip3 install numpy Ubuntu 16.04 # libboost sudo apt-get install -y --no-install-recommends libboost-all-dev cd /usr/lib/x86_64-linux-gnu sudo ln -s libboost_python-py35.so libboost_python3.so Ubuntu 18.04 #libboost sudo apt-get install -y --no-install-recommends libboost-all-dev sudo apt install libboost-python1.62.0","title":"Environment Setup"},{"location":"installation/#building-and-installation_1","text":"set ENV InferenceEngine_DIR, CPU_EXTENSION_LIB and GFLAGS_LIB export InferenceEngine_DIR=/opt/openvino_toolkit/dldt/inference-engine/build/ export CPU_EXTENSION_LIB=/opt/openvino_toolkit/dldt/inference-engine/bin/intel64/Release/lib/libcpu_extension.so export GFLAGS_LIB=/opt/openvino_toolkit/dldt/inference-engine/bin/intel64/Release/lib/libgflags_nothreads.a Install ROS2_OpenVINO packages mkdir -p ~/ros2_overlay_ws/src cd ~/ros2_overlay_ws/src git clone https://github.com/intel/ros2_openvino_toolkit Build package source ~/ros2_ws/install/local_setup.bash cd ~/ros2_overlay_ws colcon build --symlink-install source ./install/local_setup.bash sudo mkdir -p /opt/openvino_toolkit sudo ln -s ~/ros2_overlay_ws/src/ros2_openvino_toolkit /opt/openvino_toolkit/ros2_openvino_toolkit Note :In pipeline_people_oss.yaml and pipeline_object_oss.yaml ,options for inputs parameter: StandardCamera or RealSenseCamera. Default is StandardCamera. * run sample code with parameters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_people_oss.yaml run object detection sample code with paramters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_object_oss.yaml","title":"Building and Installation"},{"location":"preparation/","text":"Preparation Hardware An x86_64 computer running Ubuntu 16.04. NOTE: OS X and Windows are not supported yet Intel\u00ae RealSense\u2122 Devices \u2122 Neural Compute Stick ROS2 and OpenCV 3.x Install ROS2 Crystal ( guide ) Install OpenCV 3.x( guide ) Install OpenVINO( guide ) Intel\u00ae Graphics Compute Runtime for OpenCL\u2122 Driver components should be installed after complete the installation of OpenVINO ROS2 base packages Install ros2 vision_opencv Install ros2_object_msgs Install ros2_message_filters","title":"Preparation"},{"location":"preparation/#preparation","text":"","title":"Preparation"},{"location":"preparation/#hardware","text":"An x86_64 computer running Ubuntu 16.04. NOTE: OS X and Windows are not supported yet Intel\u00ae RealSense\u2122 Devices \u2122 Neural Compute Stick","title":"Hardware"},{"location":"preparation/#ros2-and-opencv-3x","text":"Install ROS2 Crystal ( guide ) Install OpenCV 3.x( guide ) Install OpenVINO( guide )","title":"ROS2 and OpenCV 3.x"},{"location":"preparation/#intel-graphics-compute-runtime-for-opencltm-driver-components-should-be-installed-after-complete-the-installation-of-openvino","text":"","title":"Intel\u00ae Graphics Compute Runtime for OpenCL\u2122 Driver components should be installed after complete the installation of OpenVINO"},{"location":"preparation/#ros2-base-packages","text":"Install ros2 vision_opencv Install ros2_object_msgs Install ros2_message_filters","title":"ROS2 base packages"},{"location":"quickstart/","text":"Quick Start NOTE: All projects are depend on Intel Reanlsense cameras. If use other RGBD sensers, you may need to modify the source code according to instructions as follows. ros2_intel_realsense 1 Overview These are packages for using Intel RealSense cameras (D400 series) with ROS2. 2 Running the demo 2.1 Start the camera node To start the camera node in ROS2, plug in the camera, then type the following command: # To launch with \"ros2 run\" $ ros2 run realsense_ros2_camera realsense_ros2_camera # OR, to invoke the executable directly $ realsense_ros2_camera This will stream all camera sensors and publish on the appropriate ROS2 topics. PointCloud2 is enabled by default, till we provide ROS2 python launch options. 2.2 View camera data To start the camera node in ROS2 and view the depth pointcloud in rviz via ros1_bridge : # firstly self-build ros1_bridge, than refer to section \"Example 1b: ROS 2 talker and ROS 1 listener\" # in console #1 launch roscore $ source /opt/ros/kinetic/setup.bash $ roscore # in console #2 launch ros1_bridge $ source /opt/ros/kinetic/setup.bash $ cd ~/ros2_ws $ source ./install/local_setup.bash $ export ROS_MASTER_URI=http://localhost:11311 $ ros2 run ros1_bridge dynamic_bridge # in console #3 launch rviz $ source /opt/ros/kinetic/setup.bash $ rosrun rviz rviz -d ~/ros2_ws/src/ros2_intel_realsense/realsense_ros2_camera/rviz/ros2.rviz # in console #4 launch realsense_ros2_camera $ source ~/ros2_ws/install/local_setup.bash $ realsense_ros2_camera This will launch RViz and display the five streams: color, depth, infra1, infra2, pointcloud. NOTE: In case PointCloud2 stream is not observed, try stop the \"realsense_ros2_camera\" and re-launch this node from console #4. This's a known issue and workaround is made (right fixing in ros1_bridge, details discussed in ROS discourse ). NOTE: Visulization in ROS2 pending on rviz2 . 3 Interfaces /camera/depth/image_rect_raw /camera/color/image_raw /camera/infra1/image_rect_raw /camera/infra2/image_rect_raw /camera/depth/color/points 4 Known Issues This ROS2 node does not currently provide any dynamic reconfigure support for camera properties/presets. We support Ubuntu Linux Xenial Xerus 16.04 on 64-bit, but not support Mac OS X 10.12 (Sierra) and Windows 10 yet. 5 TODO A few features to be ported from the latest realsense_ros_camera v2.0.2 RGB-D point cloud (depth_registered) Preset/Controls ros2_intel_movidius_ncs 1 Overview The Movidius\u2122 Neural Compute Stick ( NCS ) is a tiny fanless deep learning device that you can use to learn AI programming at the edge. NCS is powered by the same low power high performance Movidius\u2122 Vision Processing Unit ( VPU ) that can be found in millions of smart security cameras, gesture controlled drones, industrial machine vision equipment, and more. This project is a ROS2 wrapper for NC API of NCSDK , providing the following features: A ROS2 service for object classification and detection of a static image file A ROS2 publisher for object classification and detection of a video stream from a RGB camera Demo applications to show the capabilities of ROS2 service and publisher Support multiple CNN models of Caffe and Tensorflow 2 Running the Demo 2.1 Classification 2.1.1 Supported CNN Models # Table1 CNN Model Framework Usage AlexNet Caffe Image / Video GoogLeNet Caffe Image / Video SqueezeNet Caffe Image / Video Inception_v1 Tensorflow Image / Video Inception_v2 Tensorflow Image / Video Inception_v3 Tensorflow Image / Video Inception_v4 Tensorflow Image / Video MobileNet Tensorflow Image / Video 2.1.2 Classification Result with GoogLeNet 2.1.3 Running the Demo Static Image Video Streaming 2.2 Detection 2.2.1 Supported CNN Models CNN Model Framework Usage MobileNetSSD(Recommended) Caffe Image / Video TinyYolo_v1 Caffe Image / Video 2.2.2 Detection Result with MobileNetSSD 2.2.3 Running the Demo Static Image Video Streaming 3 Interfaces 3.1 Topic Classification: /movidius_ncs_nodelet/classified_objects Detection: /movidius_ncs_nodelet/detected_objects 3.2 Service Classification: /movidius_ncs_image/classify_object Detection: /movidius_ncs_image/detect_object 4 Known Issues Only absolute path of image file supported in image inference demo Only test on RealSense D400 series camera 5 TODO Keep synchronized with ROS NCS Package ros2_object_analytic 1 Overview Object Analytics (OA) is ROS2 wrapper for realtime object detection, localization and tracking. These packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM. It consumes sensor_msgs::PointClould2 data delivered by RGB-D camera, publishing topics on object detection , object tracking , and object localization in 3D camera coordination system. OA keeps integrating with various \"state-of-the-art\" algorithms. Object detection offload to VPU, Intel Movidius NCS, with MobileNet SSD model and Caffe framework. 2 Running the demo Step 1. [In terminal 1] Launch Realsense camera node # Terminal 1: . <install-space-with-realsense-ros2-camera>/local_setup.bash realsense_ros2_camera Step 2. [In terminal 1] Launch NCS and OA node # Terminal 2 . <install-space-with-object-analytics-launch>/local_setup.bash echo -e \"param_file: mobilenetssd.yaml\\ninput_topic: /object_analytics/rgb\" > `ros2 pkg prefix movidius_ncs_launch`/share/movidius_ncs_launch/config/default.yaml launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py Step 3. [In terminal 1] Launch OA Rviz # Terminal 3 . <install-space-with-object-analytics-launch>/local_setup.bash launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/object_rviz.py 3 Interfaces 3.1 Subscribed topics /movidius_ncs_stream/detected_objects ( object_msgs::msg::ObjectsInBoxes ) 3.2 Published topics /object_analytics/rgb ( sensor_msgs::msg::Image ) /object_analytics/pointcloud ( sensor_msgs::msg::PointCloud2 ) /object_analytics/localization ( object_analytics_msgs::msg::ObjectsInBoxes3D ) /object_analytics/tracking ( object_analytics_msgs::msg::TrackedObjects ) 3.3 Customize launch By default, object analytics will launch both tracking and localization features, but either tracking or localization or both can be dropped. Detailed please refer comments embedded in launch file. 4 Known issues -- 5 TODO -- ros2_object_map 1 Introduction ros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses ros2_object_analytics for object detection. 2 Running the demo Step 1. [In terminal 1] Launch Realsense Camera node # terminal 1 source ~/ros2_ws/install/local_setup.bash realsense_ros2_camera Step 2. [In terminal 2] Launch object_analytics node # terminal 2 source ~/ros2_ws/install/local_setup.bash launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py Step 3. [In terminal 3] Launch ros2_object_map node # terminal 3 source ~/ros2_ws/install/local_setup.bash ros2 run object_map object_map_node Step 4. [In terminal 4] Launch ROS2 rviz2 # terminal 6 source ~/ros2_ws/install/local_setup.bash rosrun rviz2 rviz2 within rviz gui, click \"Add\", and select \"MarkerArray\", then input \"/object_map/Markers\" into \"Marker Topic\" 3 Interfaces 3.1 Topic /object_map/Markers : Publish MarkerArray on RVIZ /object_map/map_save : Subscribe map_save topic to save object maps /movidius_ncs_stream/detected_objects : Subscribe ObjectsInBoxes from object_analytics /object_analytics/tracking : Subscribe TrackedObjects from object_analytics /object_analytics/localization : Subscribe ObjectsInBoxes3D from object_analytics 3.2 Save object map ros2 topic pub --once /object_map/map_save std_msgs/Int32 -1 4 Known Issues * Map tag cannot be correctly displayed in Rviz while robot is moving reason: tf2 python api is not supported in ROS2 currrently next step: will implement it while tf2-python api is ready in ROS2 * Configure File is not supported reason: yaml configure file and dynamic configure file are not supported in ROS2 currently next step: will implement it while it is ready in next release of ROS2 5 TODO -- ros2_moving_object 1. Overview Moving Object component is addressing moving objects based on messages generated by Object Analytics ros2_object_analytics . ros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding motion information , i.e., the velocity information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance. Thanks to ros2_object_analytics and ros2_intel_movidius_ncs to provide an AI solution for object detection, tracking and localization. See the umbrella wiki page to learn the hierarchical data flow and overview description for the related components. This component involves 2 ROS2 packages: - moving_object : the main package covering logic of moving object analysis and information generation. - moving_object_msgs : the message package storing the motion information of moving objects and published into ROS2 system. 2. Running the demo #### Step 1. [In terminal 1] Launch realsense camera node. source </ros2/install/dir>/local_setup.bash source </my/overlay_ws/dir>/install/local_setup.bash realsense_ros2_camera Step 2. [In terminal 2] Launch object analysis node. source </ros2/install/dir>/local_setup.bash source </my/overlay_ws/dir>/install/local_setup.bash echo -e \"param_file: alexnet.yaml\\ninput_topic: /object_analytics/rgb > src/ros2_intel_movidius_ncs/movidius_ncs_launch/config/default.yaml\" launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py Step 3. [In terminal 3] Launch moving object node. source </ros2/install/dir>/local_setup.bash source </my/overlay_ws/dir>/install/local_setup.bash ros2 run moving_object moving_object 3. Interfaces ros2_moving_object package publishes some messages to indicate different status/data. - /moving_object/moving_objects merges info from the 3 input messages into one message and calculating (on demand) the velocity info of the tracked moving objects. 4. Known issues -- 5. TODO -- ros2_openvino_toolkit 1. Overview The OpenVINO\u2122 toolkit quickly deploys applications and solutions that emulate human vision. Based on Convolutional Neural Networks (CNN), the Toolkit extends computer vision (CV) workloads across Intel\u00ae hardware, maximizing performance. This project is a ROS2 wrapper for CV API of OpenVINO\u2122 , providing the following features: Support CPU and GPU platforms Support standard USB camera and Intel\u00ae RealSense\u2122 camera Support Video or Image file as detection source Face detection Emotion recognition Age and gender recognition Head pose recognition Object detection * Demo application to show above detection and recognitions 2. Running the demo: 2.1 Build from Binary: Preparation copy label files (excute once ) sudo cp /opt/openvino_toolkit/ros2_openvino_toolkit/data/labels/emotions-recognition/FP32/emotions-recognition-retail-0003.labels /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP32 set OpenVINO toolkit ENV source /opt/intel/computer_vision_sdk/bin/setupvars.sh Preparation copy label files (excute once ) sudo cp /opt/openvino_toolkit/ros2_openvino_toolkit/data/labels/emotions-recognition/FP32/emotions-recognition-retail-0003.labels /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP32 set OpenVINO toolkit ENV source /opt/intel/computer_vision_sdk/bin/setupvars.sh set ENV LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib Note :In pipeline_people.yaml and pipeline_object.yaml ,options for inputs parameter: StandardCamera or RealSenseCamera. Default is StandardCamera. * run sample code with parameters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_people.yaml run object detection sample code with paramters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_object.yaml * set ENV LD_LIBRARY_PATH ``` export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib ``` Note :In pipeline_people.yaml and pipeline_object.yaml ,options for inputs parameter: StandardCamera or RealSenseCamera. Default is StandardCamera. * run sample code with parameters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_people.yaml run object detection sample code with paramters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_object.yaml 2.2 Build from source code: Preparation -- * download model file (excute once ) ``` cd /opt/openvino_toolkit/open_model_zoo/model_downloader python3 downloader.py --name face-detection-adas-0001 python3 downloader.py --name age-gender-recognition-retail-0013 python3 downloader.py --name emotions-recognition-retail-0003 python3 downloader.py --name head-pose-estimation-adas-0001 python3 downloader.py --name person-vehicle-bike-detection-crossroad-0078 ``` * copy label files (excute _once_)<br> ``` sudo cp /opt/openvino_toolkit/ros2_openvino_toolkit/data/labels/emotions-recognition/FP32/emotions-recognition-retail-0003.labels /opt/openvino_toolkit/open_model_zoo/model_downloader/Retail/object_attributes/emotions_recognition/0003/dldt ``` * set ENV LD_LIBRARY_PATH<br> ``` export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/openvino_toolkit/dldt/inference-engine/bin/intel64/Release/lib ``` 3. Interfaces Topic Face Detection: /openvino_toolkit/faces ( object_msgs:msg:ObjectsInBoxes ) Emotion Detection: /openvino_toolkit/emotions ( people_msgs:msg:EmotionsStamped ) Age and Gender Detection: /openvino_toolkit/age_genders ( people_msgs:msg:AgeGenderStamped ) Head Pose: /openvino_toolkit/headposes ( people_msgs:msg:HeadPoseStamped ) 4. Known Issues Parameters \"-m_ag, -m_hp, -m_em\" should be optional, but samples throw exception without them. Parameters \"-n_ag, -n_hp, -n_em\" doesn't work. The maximum number of face/age/headpose/emotion is always 16. Standard USB camera can be unexpected launched with input parameter \"-i RealSenseCamera\". 5. TODO --","title":"Quick Start"},{"location":"quickstart/#quick-start","text":"NOTE: All projects are depend on Intel Reanlsense cameras. If use other RGBD sensers, you may need to modify the source code according to instructions as follows.","title":"Quick Start"},{"location":"quickstart/#ros2_intel_realsense","text":"","title":"ros2_intel_realsense"},{"location":"quickstart/#1-overview","text":"These are packages for using Intel RealSense cameras (D400 series) with ROS2.","title":"1 Overview"},{"location":"quickstart/#2-running-the-demo","text":"","title":"2 Running the demo"},{"location":"quickstart/#21-start-the-camera-node","text":"To start the camera node in ROS2, plug in the camera, then type the following command: # To launch with \"ros2 run\" $ ros2 run realsense_ros2_camera realsense_ros2_camera # OR, to invoke the executable directly $ realsense_ros2_camera This will stream all camera sensors and publish on the appropriate ROS2 topics. PointCloud2 is enabled by default, till we provide ROS2 python launch options.","title":"2.1 Start the camera node"},{"location":"quickstart/#22-view-camera-data","text":"To start the camera node in ROS2 and view the depth pointcloud in rviz via ros1_bridge : # firstly self-build ros1_bridge, than refer to section \"Example 1b: ROS 2 talker and ROS 1 listener\" # in console #1 launch roscore $ source /opt/ros/kinetic/setup.bash $ roscore # in console #2 launch ros1_bridge $ source /opt/ros/kinetic/setup.bash $ cd ~/ros2_ws $ source ./install/local_setup.bash $ export ROS_MASTER_URI=http://localhost:11311 $ ros2 run ros1_bridge dynamic_bridge # in console #3 launch rviz $ source /opt/ros/kinetic/setup.bash $ rosrun rviz rviz -d ~/ros2_ws/src/ros2_intel_realsense/realsense_ros2_camera/rviz/ros2.rviz # in console #4 launch realsense_ros2_camera $ source ~/ros2_ws/install/local_setup.bash $ realsense_ros2_camera This will launch RViz and display the five streams: color, depth, infra1, infra2, pointcloud. NOTE: In case PointCloud2 stream is not observed, try stop the \"realsense_ros2_camera\" and re-launch this node from console #4. This's a known issue and workaround is made (right fixing in ros1_bridge, details discussed in ROS discourse ). NOTE: Visulization in ROS2 pending on rviz2 .","title":"2.2 View camera data"},{"location":"quickstart/#3-interfaces","text":"/camera/depth/image_rect_raw /camera/color/image_raw /camera/infra1/image_rect_raw /camera/infra2/image_rect_raw /camera/depth/color/points","title":"3 Interfaces"},{"location":"quickstart/#4-known-issues","text":"This ROS2 node does not currently provide any dynamic reconfigure support for camera properties/presets. We support Ubuntu Linux Xenial Xerus 16.04 on 64-bit, but not support Mac OS X 10.12 (Sierra) and Windows 10 yet.","title":"4 Known Issues"},{"location":"quickstart/#5-todo","text":"A few features to be ported from the latest realsense_ros_camera v2.0.2 RGB-D point cloud (depth_registered) Preset/Controls","title":"5 TODO"},{"location":"quickstart/#ros2_intel_movidius_ncs","text":"","title":"ros2_intel_movidius_ncs"},{"location":"quickstart/#1-overview_1","text":"The Movidius\u2122 Neural Compute Stick ( NCS ) is a tiny fanless deep learning device that you can use to learn AI programming at the edge. NCS is powered by the same low power high performance Movidius\u2122 Vision Processing Unit ( VPU ) that can be found in millions of smart security cameras, gesture controlled drones, industrial machine vision equipment, and more. This project is a ROS2 wrapper for NC API of NCSDK , providing the following features: A ROS2 service for object classification and detection of a static image file A ROS2 publisher for object classification and detection of a video stream from a RGB camera Demo applications to show the capabilities of ROS2 service and publisher Support multiple CNN models of Caffe and Tensorflow","title":"1 Overview"},{"location":"quickstart/#2-running-the-demo_1","text":"","title":"2 Running the Demo"},{"location":"quickstart/#21-classification","text":"","title":"2.1 Classification"},{"location":"quickstart/#211-supported-cnn-models","text":"","title":"2.1.1 Supported CNN Models"},{"location":"quickstart/#table1","text":"CNN Model Framework Usage AlexNet Caffe Image / Video GoogLeNet Caffe Image / Video SqueezeNet Caffe Image / Video Inception_v1 Tensorflow Image / Video Inception_v2 Tensorflow Image / Video Inception_v3 Tensorflow Image / Video Inception_v4 Tensorflow Image / Video MobileNet Tensorflow Image / Video","title":"# Table1"},{"location":"quickstart/#212-classification-result-with-googlenet","text":"","title":"2.1.2 Classification Result with GoogLeNet"},{"location":"quickstart/#213-running-the-demo","text":"Static Image Video Streaming","title":"2.1.3 Running the Demo"},{"location":"quickstart/#22-detection","text":"","title":"2.2 Detection"},{"location":"quickstart/#221-supported-cnn-models","text":"CNN Model Framework Usage MobileNetSSD(Recommended) Caffe Image / Video TinyYolo_v1 Caffe Image / Video","title":"2.2.1 Supported CNN Models"},{"location":"quickstart/#222-detection-result-with-mobilenetssd","text":"","title":"2.2.2 Detection Result with MobileNetSSD"},{"location":"quickstart/#223-running-the-demo","text":"Static Image Video Streaming","title":"2.2.3 Running the Demo"},{"location":"quickstart/#3-interfaces_1","text":"","title":"3 Interfaces"},{"location":"quickstart/#31-topic","text":"Classification: /movidius_ncs_nodelet/classified_objects Detection: /movidius_ncs_nodelet/detected_objects","title":"3.1 Topic"},{"location":"quickstart/#32-service","text":"Classification: /movidius_ncs_image/classify_object Detection: /movidius_ncs_image/detect_object","title":"3.2 Service"},{"location":"quickstart/#4-known-issues_1","text":"Only absolute path of image file supported in image inference demo Only test on RealSense D400 series camera","title":"4 Known Issues"},{"location":"quickstart/#5-todo_1","text":"Keep synchronized with ROS NCS Package","title":"5 TODO"},{"location":"quickstart/#ros2_object_analytic","text":"","title":"ros2_object_analytic"},{"location":"quickstart/#1-overview_2","text":"Object Analytics (OA) is ROS2 wrapper for realtime object detection, localization and tracking. These packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM. It consumes sensor_msgs::PointClould2 data delivered by RGB-D camera, publishing topics on object detection , object tracking , and object localization in 3D camera coordination system. OA keeps integrating with various \"state-of-the-art\" algorithms. Object detection offload to VPU, Intel Movidius NCS, with MobileNet SSD model and Caffe framework.","title":"1 Overview"},{"location":"quickstart/#2-running-the-demo_2","text":"","title":"2 Running the demo"},{"location":"quickstart/#step-1-in-terminal-1-launch-realsense-camera-node","text":"# Terminal 1: . <install-space-with-realsense-ros2-camera>/local_setup.bash realsense_ros2_camera","title":"Step 1. [In terminal 1] Launch Realsense camera node"},{"location":"quickstart/#step-2-in-terminal-1-launch-ncs-and-oa-node","text":"# Terminal 2 . <install-space-with-object-analytics-launch>/local_setup.bash echo -e \"param_file: mobilenetssd.yaml\\ninput_topic: /object_analytics/rgb\" > `ros2 pkg prefix movidius_ncs_launch`/share/movidius_ncs_launch/config/default.yaml launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py","title":"Step 2. [In terminal 1] Launch NCS and OA node"},{"location":"quickstart/#step-3-in-terminal-1-launch-oa-rviz","text":"# Terminal 3 . <install-space-with-object-analytics-launch>/local_setup.bash launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/object_rviz.py","title":"Step 3. [In terminal 1] Launch OA Rviz"},{"location":"quickstart/#3-interfaces_2","text":"","title":"3 Interfaces"},{"location":"quickstart/#31-subscribed-topics","text":"/movidius_ncs_stream/detected_objects ( object_msgs::msg::ObjectsInBoxes )","title":"3.1 Subscribed topics"},{"location":"quickstart/#32-published-topics","text":"/object_analytics/rgb ( sensor_msgs::msg::Image ) /object_analytics/pointcloud ( sensor_msgs::msg::PointCloud2 ) /object_analytics/localization ( object_analytics_msgs::msg::ObjectsInBoxes3D ) /object_analytics/tracking ( object_analytics_msgs::msg::TrackedObjects )","title":"3.2 Published topics"},{"location":"quickstart/#33-customize-launch","text":"By default, object analytics will launch both tracking and localization features, but either tracking or localization or both can be dropped. Detailed please refer comments embedded in launch file.","title":"3.3 Customize launch"},{"location":"quickstart/#4-known-issues_2","text":"--","title":"4 Known issues"},{"location":"quickstart/#5-todo_2","text":"--","title":"5 TODO"},{"location":"quickstart/#ros2_object_map","text":"","title":"ros2_object_map"},{"location":"quickstart/#1-introduction","text":"ros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses ros2_object_analytics for object detection.","title":"1 Introduction"},{"location":"quickstart/#2-running-the-demo_3","text":"","title":"2 Running the demo"},{"location":"quickstart/#step-1-in-terminal-1-launch-realsense-camera-node_1","text":"# terminal 1 source ~/ros2_ws/install/local_setup.bash realsense_ros2_camera","title":"Step 1. [In terminal 1] Launch Realsense Camera node"},{"location":"quickstart/#step-2-in-terminal-2-launch-object_analytics-node","text":"# terminal 2 source ~/ros2_ws/install/local_setup.bash launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py","title":"Step 2. [In terminal 2] Launch object_analytics node"},{"location":"quickstart/#step-3-in-terminal-3-launch-ros2_object_map-node","text":"# terminal 3 source ~/ros2_ws/install/local_setup.bash ros2 run object_map object_map_node","title":"Step 3. [In terminal 3] Launch ros2_object_map node"},{"location":"quickstart/#step-4-in-terminal-4launch-ros2-rviz2","text":"# terminal 6 source ~/ros2_ws/install/local_setup.bash rosrun rviz2 rviz2 within rviz gui, click \"Add\", and select \"MarkerArray\", then input \"/object_map/Markers\" into \"Marker Topic\"","title":"Step 4. [In terminal 4]Launch ROS2 rviz2"},{"location":"quickstart/#3-interfaces_3","text":"","title":"3 Interfaces"},{"location":"quickstart/#31-topic_1","text":"/object_map/Markers : Publish MarkerArray on RVIZ /object_map/map_save : Subscribe map_save topic to save object maps /movidius_ncs_stream/detected_objects : Subscribe ObjectsInBoxes from object_analytics /object_analytics/tracking : Subscribe TrackedObjects from object_analytics /object_analytics/localization : Subscribe ObjectsInBoxes3D from object_analytics","title":"3.1 Topic"},{"location":"quickstart/#32-save-object-map","text":"ros2 topic pub --once /object_map/map_save std_msgs/Int32 -1","title":"3.2 Save object map"},{"location":"quickstart/#4-known-issues_3","text":"","title":"4 Known Issues"},{"location":"quickstart/#map-tag-cannot-be-correctly-displayed-in-rviz-while-robot-is-moving","text":"reason: tf2 python api is not supported in ROS2 currrently next step: will implement it while tf2-python api is ready in ROS2","title":"* Map tag cannot be correctly displayed in Rviz while robot is moving"},{"location":"quickstart/#configure-file-is-not-supported","text":"reason: yaml configure file and dynamic configure file are not supported in ROS2 currently next step: will implement it while it is ready in next release of ROS2","title":"* Configure File is not supported"},{"location":"quickstart/#5-todo_3","text":"--","title":"5 TODO"},{"location":"quickstart/#ros2_moving_object","text":"","title":"ros2_moving_object"},{"location":"quickstart/#1-overview_3","text":"Moving Object component is addressing moving objects based on messages generated by Object Analytics ros2_object_analytics . ros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding motion information , i.e., the velocity information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance. Thanks to ros2_object_analytics and ros2_intel_movidius_ncs to provide an AI solution for object detection, tracking and localization. See the umbrella wiki page to learn the hierarchical data flow and overview description for the related components. This component involves 2 ROS2 packages: - moving_object : the main package covering logic of moving object analysis and information generation. - moving_object_msgs : the message package storing the motion information of moving objects and published into ROS2 system.","title":"1. Overview"},{"location":"quickstart/#2-running-the-demo_4","text":"#### Step 1. [In terminal 1] Launch realsense camera node. source </ros2/install/dir>/local_setup.bash source </my/overlay_ws/dir>/install/local_setup.bash realsense_ros2_camera","title":"2. Running the demo"},{"location":"quickstart/#step-2-in-terminal-2-launch-object-analysis-node","text":"source </ros2/install/dir>/local_setup.bash source </my/overlay_ws/dir>/install/local_setup.bash echo -e \"param_file: alexnet.yaml\\ninput_topic: /object_analytics/rgb > src/ros2_intel_movidius_ncs/movidius_ncs_launch/config/default.yaml\" launch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py","title":"Step 2. [In terminal 2] Launch object analysis node."},{"location":"quickstart/#step-3-in-terminal-3-launch-moving-object-node","text":"source </ros2/install/dir>/local_setup.bash source </my/overlay_ws/dir>/install/local_setup.bash ros2 run moving_object moving_object","title":"Step 3. [In terminal 3] Launch moving object node."},{"location":"quickstart/#3-interfaces_4","text":"ros2_moving_object package publishes some messages to indicate different status/data. - /moving_object/moving_objects merges info from the 3 input messages into one message and calculating (on demand) the velocity info of the tracked moving objects.","title":"3. Interfaces"},{"location":"quickstart/#4-known-issues_4","text":"--","title":"4. Known issues"},{"location":"quickstart/#5-todo_4","text":"--","title":"5. TODO"},{"location":"quickstart/#ros2_openvino_toolkit","text":"","title":"ros2_openvino_toolkit"},{"location":"quickstart/#1-overview_4","text":"The OpenVINO\u2122 toolkit quickly deploys applications and solutions that emulate human vision. Based on Convolutional Neural Networks (CNN), the Toolkit extends computer vision (CV) workloads across Intel\u00ae hardware, maximizing performance. This project is a ROS2 wrapper for CV API of OpenVINO\u2122 , providing the following features: Support CPU and GPU platforms Support standard USB camera and Intel\u00ae RealSense\u2122 camera Support Video or Image file as detection source Face detection Emotion recognition Age and gender recognition Head pose recognition Object detection * Demo application to show above detection and recognitions","title":"1. Overview"},{"location":"quickstart/#2-running-the-demo_5","text":"","title":"2. Running the demo:"},{"location":"quickstart/#21-build-from-binary","text":"Preparation copy label files (excute once ) sudo cp /opt/openvino_toolkit/ros2_openvino_toolkit/data/labels/emotions-recognition/FP32/emotions-recognition-retail-0003.labels /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP32 set OpenVINO toolkit ENV source /opt/intel/computer_vision_sdk/bin/setupvars.sh Preparation copy label files (excute once ) sudo cp /opt/openvino_toolkit/ros2_openvino_toolkit/data/labels/emotions-recognition/FP32/emotions-recognition-retail-0003.labels /opt/intel/computer_vision_sdk/deployment_tools/intel_models/emotions-recognition-retail-0003/FP32 set OpenVINO toolkit ENV source /opt/intel/computer_vision_sdk/bin/setupvars.sh set ENV LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib Note :In pipeline_people.yaml and pipeline_object.yaml ,options for inputs parameter: StandardCamera or RealSenseCamera. Default is StandardCamera. * run sample code with parameters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_people.yaml run object detection sample code with paramters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_object.yaml * set ENV LD_LIBRARY_PATH ``` export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/computer_vision_sdk/deployment_tools/inference_engine/samples/build/intel64/Release/lib ``` Note :In pipeline_people.yaml and pipeline_object.yaml ,options for inputs parameter: StandardCamera or RealSenseCamera. Default is StandardCamera. * run sample code with parameters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_people.yaml run object detection sample code with paramters extracted from yaml . ros2 run dynamic_vino_sample pipeline_with_params -config /opt/openvino_toolkit/ros2_openvino_toolkit/sample/param/pipeline_object.yaml","title":"2.1 Build from Binary:"},{"location":"quickstart/#22-build-from-source-code","text":"Preparation -- * download model file (excute once ) ``` cd /opt/openvino_toolkit/open_model_zoo/model_downloader python3 downloader.py --name face-detection-adas-0001 python3 downloader.py --name age-gender-recognition-retail-0013 python3 downloader.py --name emotions-recognition-retail-0003 python3 downloader.py --name head-pose-estimation-adas-0001 python3 downloader.py --name person-vehicle-bike-detection-crossroad-0078 ``` * copy label files (excute _once_)<br> ``` sudo cp /opt/openvino_toolkit/ros2_openvino_toolkit/data/labels/emotions-recognition/FP32/emotions-recognition-retail-0003.labels /opt/openvino_toolkit/open_model_zoo/model_downloader/Retail/object_attributes/emotions_recognition/0003/dldt ``` * set ENV LD_LIBRARY_PATH<br> ``` export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/openvino_toolkit/dldt/inference-engine/bin/intel64/Release/lib ```","title":"2.2 Build from source code:"},{"location":"quickstart/#3-interfaces_5","text":"","title":"3. Interfaces"},{"location":"quickstart/#topic","text":"Face Detection: /openvino_toolkit/faces ( object_msgs:msg:ObjectsInBoxes ) Emotion Detection: /openvino_toolkit/emotions ( people_msgs:msg:EmotionsStamped ) Age and Gender Detection: /openvino_toolkit/age_genders ( people_msgs:msg:AgeGenderStamped ) Head Pose: /openvino_toolkit/headposes ( people_msgs:msg:HeadPoseStamped )","title":"Topic"},{"location":"quickstart/#4-known-issues_5","text":"Parameters \"-m_ag, -m_hp, -m_em\" should be optional, but samples throw exception without them. Parameters \"-n_ag, -n_hp, -n_em\" doesn't work. The maximum number of face/age/headpose/emotion is always 16. Standard USB camera can be unexpected launched with input parameter \"-i RealSenseCamera\".","title":"4. Known Issues"},{"location":"quickstart/#5-todo_5","text":"--","title":"5. TODO"}]}
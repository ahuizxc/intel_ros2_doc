{
    "docs": [
        {
            "location": "/",
            "text": "Intel Ros2 Project Tutorial\n\n\nOverview\n\n\nIntel Ros2 Project contains several ROS2 packages in object classification, detection, localization and tracking and SLAM.\n\n\nPackage Lists\n\n\nros2_intel_realsense\n\n\n\n\nros2_intel_realsense for using Intel RealSense cameras (D400 series) with ROS2.\n\n\n\n\nros2_intel_movidius_ncs\n\n\n\n\n\n\nros2_intel_movidius_ncs is a ROS2 wrapper for NC API of NCSDK, providing the following features:\n\n\n\n\n\n\nA ROS2 service for object classification and detection of a static image file.\n\n\n\n\n\n\nA ROS2 publisher for object classification and detection of a video stream from a RGB camera.\n\n\n\n\n\n\nDemo applications to show the capabilities of ROS2 service and publisher.\n\n\n\n\n\n\nSupport multiple CNN models of Caffe and Tensorflow.\n\n\n\n\n\n\n\n\n\n\nros2_object_analytics\n\n\n\n\nros2_object_analytics is a ROS2 wrapper for realtime object detection, localization and tracking. These packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM.\n\n\n\n\nros2_object_map\n\n\n\n\nros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses ros2_object_analytics for object detection.\n\n\n\n\nros2_moving_object\n\n\n\n\nros2_moving_object is addressing moving objects based on messages generated by Object Analytics ros2_object_analytics. ros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding motion information, i.e., the velocity information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance.\n\n\n\n\nLicense\n\n\nCopyright 2018 Intel Corporation\n\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this project except in compliance with the License.\nYou may obtain a copy of the License at\n\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\n\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\n*\nOther names and brands may be claimed as the property of others\n\n\nAny security issue should be reported using process at https://01.org/security",
            "title": "Home"
        },
        {
            "location": "/#intel-ros2-project-tutorial",
            "text": "",
            "title": "Intel Ros2 Project Tutorial"
        },
        {
            "location": "/#overview",
            "text": "Intel Ros2 Project contains several ROS2 packages in object classification, detection, localization and tracking and SLAM.",
            "title": "Overview"
        },
        {
            "location": "/#package-lists",
            "text": "ros2_intel_realsense   ros2_intel_realsense for using Intel RealSense cameras (D400 series) with ROS2.   ros2_intel_movidius_ncs    ros2_intel_movidius_ncs is a ROS2 wrapper for NC API of NCSDK, providing the following features:    A ROS2 service for object classification and detection of a static image file.    A ROS2 publisher for object classification and detection of a video stream from a RGB camera.    Demo applications to show the capabilities of ROS2 service and publisher.    Support multiple CNN models of Caffe and Tensorflow.      ros2_object_analytics   ros2_object_analytics is a ROS2 wrapper for realtime object detection, localization and tracking. These packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM.   ros2_object_map   ros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses ros2_object_analytics for object detection.   ros2_moving_object   ros2_moving_object is addressing moving objects based on messages generated by Object Analytics ros2_object_analytics. ros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding motion information, i.e., the velocity information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance.",
            "title": "Package Lists"
        },
        {
            "location": "/#license",
            "text": "Copyright 2018 Intel Corporation  Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this project except in compliance with the License.\nYou may obtain a copy of the License at  http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.  * Other names and brands may be claimed as the property of others  Any security issue should be reported using process at https://01.org/security",
            "title": "License"
        },
        {
            "location": "/preparation/",
            "text": "Preparation\n\n\nHardware\n\n\n\n\nAn x86_64 computer running Ubuntu 16.04.\n\n\n\n\nNOTE: OS X and Windows are not supported yet\n\n\n\n\n\n\nIntel\u00ae RealSense\u2122 Devices\n  \n\n\n\n\n\n\n\u2122 Neural Compute Stick\n\n\n\n\n\n\nROS1(Optional), ROS2 and OpenCV 3.x\n\n\n\n\nInstall ROS1 kinetic(\nguide\n)\n\n\nInstall ROS2 Bouncy (\nguide\n)\n\n\nInstall OpenCV 3.x(\nguide\n)\n\n\n\n\nROS2 base packages\n\n\n\n\n\n\nInstall \nros2 vision_opencv\n\n\n\n\n\n\nInstall \nros2_object_msgs\n\n\n\n\n\n\nInstall \nros2_message_filters",
            "title": "Preparation"
        },
        {
            "location": "/preparation/#preparation",
            "text": "",
            "title": "Preparation"
        },
        {
            "location": "/preparation/#hardware",
            "text": "An x86_64 computer running Ubuntu 16.04.   NOTE: OS X and Windows are not supported yet    Intel\u00ae RealSense\u2122 Devices       \u2122 Neural Compute Stick",
            "title": "Hardware"
        },
        {
            "location": "/preparation/#ros1optional-ros2-and-opencv-3x",
            "text": "Install ROS1 kinetic( guide )  Install ROS2 Bouncy ( guide )  Install OpenCV 3.x( guide )",
            "title": "ROS1(Optional), ROS2 and OpenCV 3.x"
        },
        {
            "location": "/preparation/#ros2-base-packages",
            "text": "Install  ros2 vision_opencv    Install  ros2_object_msgs    Install  ros2_message_filters",
            "title": "ROS2 base packages"
        },
        {
            "location": "/installation/",
            "text": "Installation Instructions\n\n\n Install the Intel\u00ae RealSense\u2122 SDK 2.0\n\n\n\n\nInstall tag v2.9.1 \nIntel\u00ae RealSense\u2122 SDK 2.0\n and follow the instructions under \nLinux Installation\n.\n\n\n\n\n\n\nNote:\n Use \ngit checkout v2.9.1\n to switch to the v2.9.1 branch.\n\n\n\n\nInstall ROS1 Kinetic(Optional)\n\n\n\n\nUbuntu install of ROS Kinetic(\nros-kinetic-desktop-full\n)\n\n\n\n\nInstall ROS2 Bouncy\n\n\n\n\nUbuntu install of ROS Bouncy\n\n\n\n\n\n\n Source the environment\n\n\n\n\ncd ~/ros2_ws\nsource install/local_setup.bash\n\n\n\n\nInstall ROS2 Base Packages\n\n\n1. Install \nros2 vision_opencv\n\n\ncd ~/ros2_ws\nsource install/local_setup.bash\n\n# Creating a new ROS2 workspace 'ros2_overlay_ws' instead of using 'ros2_ws' is recommended\nmkdir -p ~/ros2_overlay_ws/src\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/ros-perception/vision_opencv.git\ngit checkout ros2\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install\nsource ~/ros2_overlay_ws/install/local_setup.bash\n\n\n\n\n2. Install \nros2_object_msgs\n\n\ncd ~/ros2_overlay_ws/src\n# Clone the ros2_object_msgs repository and build use colcon\ngit clone https://github.com/intel/ros2_object_msgs.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select object_msgs\nsource ~/ros2_overlay_ws/install/local_setup.bash\n\n\n\n\n3. Install \nros2_message_filters\n\n\ncd /usr/lib/x86_64-linux-gnu\n# Create a symbol link from libboost_python-py35.so to libboost_python3.so\nsudo ln -s libboost_python-py35.so libboost_python3.so\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_message_filters.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select message_filters\nsource ~/ros2_overlay_ws/install/local_setup.bash\n\n\n\n\nInstall Intel ROS2 Packages\n\n\n 1. Install \nros2_intel_realsense\n\n\n# Goto the new ROS workspace step 4 created before\ncd ~/ros2_overlay_ws/src\n# Clone the latest Intel\u00ae RealSense\u2122 ROS2 repository and build use colcon\ngit clone https://github.com/intel/ros2_intel_realsense.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select realsense_camera_msgs realsense_ros2_camera\nsource ~/ros2_overlay_ws/install/local_setup.bash\n# Create a symbol link from libusb.a to libusb-1.0.a, otherwise \"libusb.a\" is probably not to be found by librealsense\nsudo ln -s /usr/lib/x86_64-linux-gnu/libusb-1.0.a /usr/lib/libusb.a\n\n\n\n\n 2. Install \nros2_intel_movidius_ncs\n\n\n# Install [NCSDK 1.x](https://github.com/movidius/ncsdk) and [NCAPPZOO](https://github.com/movidius/ncappzoo) at first\n# create  workspace to install libraries ros2_intel_moidius_ncs relies on\nmkdir -p ~/workspace/libraries\ncd ~/workspace/libraries\n# install ncsdk and ncappzoo\ngit clone https://github.com/movidius/ncsdk.git\ngit clone https://github.com/movidius/ncappzoo.git\ncd ~/workspace/libraries/ncsdk\nsudo make install\nexport PYTHONPATH=\"${PYTHONPATH}:/opt/movidius/caffe/python\"\n# Download and compile the object detection model\ncd ~/workspace/libraries/ncappzoo/caffe/\nsudo make\ncd ~/workspace/libraries/ncappzoo/tensorflow/\nsudo make\n# NCSDK should be installed in /opt/movidius by default. Create a symbol link in /opt/movidius to NCAPPZOO\nsudo ln -s ~/workspace/libraries/ncappzoo /opt/movidius/ncappzoo\n\n\n# Install ros2_intel_movidius_ncs\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_intel_movidius_ncs.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select movidius_ncs_example  movidius_ncs_image  movidius_ncs_launch  movidius_ncs_lib  movidius_ncs_stream\nsource ~/ros2_overlay_ws/install/local_setup.bash\n\n\n\n\n 3. Install \nros2_object_analytics\n\n\n# Install pcl_conversions package at first\ncd ~/ros2_ws/src\ngit clone https://github.com/ros2/pcl_conversions.git\ncd pcl_conversions\ngit checkout bouncy\ncd ~/ros2_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select pcl_conversions\n\n# Install ros2_object_analytics\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_object_analytics.git\ncd ..\nsource ~/ros2_ws/install/local_setup.bash \ncolcon build --symlink-install --packages-select object_analytics_launch  object_analytics_node object_analytics_msgs object_analytics_rviz\nsource ~/ros2_overlay_ws/install/local.setup.bash\n\n\n\n\n 4. Install \nros2_object_map\n(Depends on ROS1)\n\n\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_object_map.git\ncd ..\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select object_map object_map_msgs\nsource ~/ros2_overlay_ws/install/local.setup.bash\n\n\n\n\n 5. Install \nros2_moving_object\n(Depends on ROS1)\n\n\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_moving_object.git\ncd ..\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select moving_object moving_object_msgs\nsource ~/ros2_overlay_ws/install/local.setup.bash",
            "title": "Installation"
        },
        {
            "location": "/installation/#installation-instructions",
            "text": "",
            "title": "Installation Instructions"
        },
        {
            "location": "/installation/#install-the-intel-realsensetm-sdk-20",
            "text": "Install tag v2.9.1  Intel\u00ae RealSense\u2122 SDK 2.0  and follow the instructions under  Linux Installation .    Note:  Use  git checkout v2.9.1  to switch to the v2.9.1 branch.",
            "title": "Install the Intel\u00ae RealSense\u2122 SDK 2.0"
        },
        {
            "location": "/installation/#install-ros1-kineticoptional",
            "text": "Ubuntu install of ROS Kinetic( ros-kinetic-desktop-full )",
            "title": "Install ROS1 Kinetic(Optional)"
        },
        {
            "location": "/installation/#install-ros2-bouncy",
            "text": "Ubuntu install of ROS Bouncy     Source the environment   cd ~/ros2_ws\nsource install/local_setup.bash",
            "title": "Install ROS2 Bouncy"
        },
        {
            "location": "/installation/#install-ros2-base-packages",
            "text": "1. Install  ros2 vision_opencv  cd ~/ros2_ws\nsource install/local_setup.bash\n\n# Creating a new ROS2 workspace 'ros2_overlay_ws' instead of using 'ros2_ws' is recommended\nmkdir -p ~/ros2_overlay_ws/src\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/ros-perception/vision_opencv.git\ngit checkout ros2\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install\nsource ~/ros2_overlay_ws/install/local_setup.bash  2. Install  ros2_object_msgs  cd ~/ros2_overlay_ws/src\n# Clone the ros2_object_msgs repository and build use colcon\ngit clone https://github.com/intel/ros2_object_msgs.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select object_msgs\nsource ~/ros2_overlay_ws/install/local_setup.bash  3. Install  ros2_message_filters  cd /usr/lib/x86_64-linux-gnu\n# Create a symbol link from libboost_python-py35.so to libboost_python3.so\nsudo ln -s libboost_python-py35.so libboost_python3.so\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_message_filters.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select message_filters\nsource ~/ros2_overlay_ws/install/local_setup.bash",
            "title": "Install ROS2 Base Packages"
        },
        {
            "location": "/installation/#install-intel-ros2-packages",
            "text": "1. Install  ros2_intel_realsense  # Goto the new ROS workspace step 4 created before\ncd ~/ros2_overlay_ws/src\n# Clone the latest Intel\u00ae RealSense\u2122 ROS2 repository and build use colcon\ngit clone https://github.com/intel/ros2_intel_realsense.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select realsense_camera_msgs realsense_ros2_camera\nsource ~/ros2_overlay_ws/install/local_setup.bash\n# Create a symbol link from libusb.a to libusb-1.0.a, otherwise \"libusb.a\" is probably not to be found by librealsense\nsudo ln -s /usr/lib/x86_64-linux-gnu/libusb-1.0.a /usr/lib/libusb.a   2. Install  ros2_intel_movidius_ncs  # Install [NCSDK 1.x](https://github.com/movidius/ncsdk) and [NCAPPZOO](https://github.com/movidius/ncappzoo) at first\n# create  workspace to install libraries ros2_intel_moidius_ncs relies on\nmkdir -p ~/workspace/libraries\ncd ~/workspace/libraries\n# install ncsdk and ncappzoo\ngit clone https://github.com/movidius/ncsdk.git\ngit clone https://github.com/movidius/ncappzoo.git\ncd ~/workspace/libraries/ncsdk\nsudo make install\nexport PYTHONPATH=\"${PYTHONPATH}:/opt/movidius/caffe/python\"\n# Download and compile the object detection model\ncd ~/workspace/libraries/ncappzoo/caffe/\nsudo make\ncd ~/workspace/libraries/ncappzoo/tensorflow/\nsudo make\n# NCSDK should be installed in /opt/movidius by default. Create a symbol link in /opt/movidius to NCAPPZOO\nsudo ln -s ~/workspace/libraries/ncappzoo /opt/movidius/ncappzoo\n\n\n# Install ros2_intel_movidius_ncs\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_intel_movidius_ncs.git\ncd ~/ros2_overlay_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select movidius_ncs_example  movidius_ncs_image  movidius_ncs_launch  movidius_ncs_lib  movidius_ncs_stream\nsource ~/ros2_overlay_ws/install/local_setup.bash   3. Install  ros2_object_analytics  # Install pcl_conversions package at first\ncd ~/ros2_ws/src\ngit clone https://github.com/ros2/pcl_conversions.git\ncd pcl_conversions\ngit checkout bouncy\ncd ~/ros2_ws\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select pcl_conversions\n\n# Install ros2_object_analytics\ncd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_object_analytics.git\ncd ..\nsource ~/ros2_ws/install/local_setup.bash \ncolcon build --symlink-install --packages-select object_analytics_launch  object_analytics_node object_analytics_msgs object_analytics_rviz\nsource ~/ros2_overlay_ws/install/local.setup.bash   4. Install  ros2_object_map (Depends on ROS1)  cd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_object_map.git\ncd ..\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select object_map object_map_msgs\nsource ~/ros2_overlay_ws/install/local.setup.bash   5. Install  ros2_moving_object (Depends on ROS1)  cd ~/ros2_overlay_ws/src\ngit clone https://github.com/intel/ros2_moving_object.git\ncd ..\nsource ~/ros2_ws/install/local_setup.bash\ncolcon build --symlink-install --packages-select moving_object moving_object_msgs\nsource ~/ros2_overlay_ws/install/local.setup.bash",
            "title": "Install Intel ROS2 Packages"
        },
        {
            "location": "/package_instruction/",
            "text": "Quick Start\n\n\nNOTE: All projects are depend on Intel Reanlsense cameras. If use other RGBD sensers, you may need to modify the source code according to instructions as follows.\n  \n\n\nros2_intel_realsense\n\n\n1 Overview\n\n\nThese are packages for using Intel RealSense cameras (D400 series) with ROS2.\n\n\n2 Running the demo\n\n\n2.1 Start the camera node\n\n\nTo start the camera node in ROS2, plug in the camera, then type the following command:\n\n\n# To launch with \"ros2 run\"\n$ ros2 run realsense_ros2_camera realsense_ros2_camera\n# OR, to invoke the executable directly\n$ realsense_ros2_camera\n\n\n\n\nThis will stream all camera sensors and publish on the appropriate ROS2 topics. PointCloud2 is enabled by default, till we provide ROS2 python launch options.\n\n\n2.2 View camera data\n\n\nTo start the camera node in ROS2 and view the depth pointcloud in rviz via \nros1_bridge\n:\n\n\n# firstly self-build ros1_bridge, than refer to section \"Example 1b: ROS 2 talker and ROS 1 listener\"\n\n# in console #1 launch roscore\n$ source /opt/ros/kinetic/setup.bash\n$ roscore\n\n# in console #2 launch ros1_bridge\n$ source /opt/ros/kinetic/setup.bash\n$ cd ~/ros2_ws\n$ source ./install/local_setup.bash\n$ export ROS_MASTER_URI=http://localhost:11311\n$ ros2 run ros1_bridge dynamic_bridge\n\n# in console #3 launch rviz\n$ source /opt/ros/kinetic/setup.bash\n$ rosrun rviz rviz -d ~/ros2_ws/src/ros2_intel_realsense/realsense_ros2_camera/rviz/ros2.rviz\n\n# in console #4 launch realsense_ros2_camera\n$ source ~/ros2_ws/install/local_setup.bash\n$ realsense_ros2_camera\n\n\n\n\nThis will launch \nRViz\n and display the five streams: color, depth, infra1, infra2, pointcloud.\n\n\nNOTE:\n In case PointCloud2 stream is not observed, try stop the \"realsense_ros2_camera\" and re-launch this node from console #4. This's a known issue and workaround is made (right fixing in ros1_bridge, details discussed in \nROS discourse\n).\n\n\nNOTE:\n Visulization in ROS2 pending on \nrviz2\n.\n\n\n\n\n3 Interfaces\n\n\n/camera/depth/image_rect_raw\n\n\n/camera/color/image_raw\n\n\n/camera/infra1/image_rect_raw\n\n\n/camera/infra2/image_rect_raw\n\n\n/camera/depth/color/points\n\n\n4 Known Issues\n\n\n\n\nThis ROS2 node does not currently provide any dynamic reconfigure support for camera properties/presets.\n\n\nWe support Ubuntu Linux Xenial Xerus 16.04 on 64-bit, but not support Mac OS X 10.12 (Sierra) and Windows 10 yet.\n\n\n\n\n5 TODO\n\n\nA few features to be ported from the latest realsense_ros_camera v2.0.2\n\n\n\n\n\n\nRGB-D point cloud (depth_registered)\n\n\n\n\n\n\nPreset/Controls\n\n\n\n\n\n\nros2_intel_movidius_ncs\n\n\n1 Overview\n\n\nThe Movidius\u2122 Neural Compute Stick (\nNCS\n) is a tiny fanless deep learning device that you can use to learn AI programming at the edge. NCS is powered by the same low power high performance Movidius\u2122 Vision Processing Unit (\nVPU\n) that can be found in millions of smart security cameras, gesture controlled drones, industrial machine vision equipment, and more.  \n\n\nThis project is a ROS2 wrapper for NC API of \nNCSDK\n, providing the following features:\n\n\n\n\n\n\nA ROS2 service for object classification and detection of a static image file\n\n\n\n\n\n\nA ROS2 publisher for object classification and detection of a video stream from a RGB camera\n\n\n\n\n\n\nDemo applications to show the capabilities of ROS2 service and publisher\n\n\n\n\n\n\nSupport multiple CNN models of Caffe and Tensorflow\n\n\n\n\n\n\n2 Running the Demo\n\n\n2.1 Classification\n\n\n2.1.1 Supported CNN Models\n\n\n# \nTable1\n\n\n\n\n\n\n\n\nCNN Model\n\n\nFramework\n\n\nUsage\n\n\n\n\n\n\n\n\n\n\nAlexNet\n\n\nCaffe\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nGoogLeNet\n\n\nCaffe\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nSqueezeNet\n\n\nCaffe\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nInception_v1\n\n\nTensorflow\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nInception_v2\n\n\nTensorflow\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nInception_v3\n\n\nTensorflow\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nInception_v4\n\n\nTensorflow\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nMobileNet\n\n\nTensorflow\n\n\nImage\n/\nVideo\n\n\n\n\n\n\n\n\n2.1.2 Classification Result with GoogLeNet\n\n\n\n\n2.1.3 Running the Demo\n\n\n\n\nStatic Image\n\n\nVideo Streaming\n\n\n\n\n2.2 Detection\n\n\n2.2.1 Supported CNN Models\n\n\n\n\n\n\n\n\nCNN Model\n\n\nFramework\n\n\nUsage\n\n\n\n\n\n\n\n\n\n\nMobileNetSSD(Recommended)\n\n\nCaffe\n\n\nImage\n/\nVideo\n\n\n\n\n\n\nTinyYolo_v1\n\n\nCaffe\n\n\nImage\n/\nVideo\n\n\n\n\n\n\n\n\n2.2.2 Detection Result with MobileNetSSD\n\n\n\n\n2.2.3 Running the Demo\n\n\n\n\nStatic Image\n\n\nVideo Streaming\n\n\n\n\n3 Interfaces\n\n\n3.1 Topic\n\n\nClassification: \n/movidius_ncs_nodelet/classified_objects\n\nDetection: \n/movidius_ncs_nodelet/detected_objects\n\n\n3.2 Service\n\n\nClassification: \n/movidius_ncs_image/classify_object\n\nDetection: \n/movidius_ncs_image/detect_object\n\n\n4 Known Issues\n\n\n\n\nOnly absolute path of image file supported in image inference demo\n\n\nOnly test on RealSense D400 series camera\n\n\n\n\n5 TODO\n\n\n\n\nKeep synchronized with \nROS NCS Package\n\n\n\n\nros2_object_analytic\n\n\n1 Overview\n\n\nObject Analytics (OA) is ROS2 wrapper for realtime object detection, localization and tracking.\nThese packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM. It consumes \nsensor_msgs::PointClould2\n data delivered by RGB-D camera, publishing topics on \nobject detection\n, \nobject tracking\n, and \nobject localization\n in 3D camera coordination system.\n\n\nOA keeps integrating with various \"state-of-the-art\" algorithms.\n\n\n\n\nObject detection offload to VPU, Intel Movidius NCS, with MobileNet SSD model and Caffe framework.\n\n\n\n\n2 Running the demo\n\n\nStep 1. \n[In terminal 1]\n Launch Realsense camera node\n\n\n# Terminal 1:\n. <install-space-with-realsense-ros2-camera>/local_setup.bash\nrealsense_ros2_camera\n\n\n\n\nStep 2. \n[In terminal 1]\n Launch NCS and OA node\n\n\n# Terminal 2\n. <install-space-with-object-analytics-launch>/local_setup.bash\necho -e \"param_file: mobilenetssd.yaml\\ninput_topic: /object_analytics/rgb\" > `ros2 pkg prefix movidius_ncs_launch`/share/movidius_ncs_launch/config/default.yaml\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py\n\n\n\n\nStep 3. \n[In terminal 1]\n Launch OA Rviz\n\n\n# Terminal 3\n. <install-space-with-object-analytics-launch>/local_setup.bash\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/object_rviz.py\n\n\n\n\n3 Interfaces\n\n\n3.1 Subscribed topics\n\n\n/movidius_ncs_stream/detected_objects (\nobject_msgs::msg::ObjectsInBoxes\n)\n\n\n3.2 Published topics\n\n\n/object_analytics/rgb (\nsensor_msgs::msg::Image\n)\n\n\n/object_analytics/pointcloud (\nsensor_msgs::msg::PointCloud2\n)\n\n\n/object_analytics/localization (\nobject_analytics_msgs::msg::ObjectsInBoxes3D\n)\n\n\n/object_analytics/tracking (\nobject_analytics_msgs::msg::TrackedObjects\n)\n\n\n3.3 Customize launch\n\n\nBy default, object analytics will launch both tracking and localization features, but either tracking or localization or both can be dropped. Detailed please refer comments embedded in launch file.\n\n\n4 Known issues\n\n\n--\n\n\n5 TODO\n\n\n--\n\n\nros2_object_map\n\n\n1 Introduction\n\n\nros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses \nros2_object_analytics\n for object detection.\n\n\n\n\n2 Running the demo\n\n\nStep 1. \n[In terminal 1]\n Launch Realsense Camera node\n\n\n# terminal 1 \nsource ~/ros2_ws/install/local_setup.bash\nrealsense_ros2_camera\n\n\n\n\nStep 2. \n[In terminal 2]\n Launch object_analytics node\n\n\n# terminal 2\nsource ~/ros2_ws/install/local_setup.bash\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py\n\n\n\n\nStep 3. \n[In terminal 3]\n Launch ros2_object_map node\n\n\n# terminal 3\nsource source ~/ros2_ws/install/local_setup.bash\nros2 run object_map object_map_node\n\n\n\n\nStep 4. \n[In terminal 4]\n Launch ROS1 roscore\n\n\n# terminal 4\nsource /opt/ros/kinetic/setup.bash\nroscore\n\n\n\n\nStep 5. \n[In terminal 5]\n Launch ROS1 bridge\n\n\n# terminal 5\nsource /opt/ros/kinetic/setup.bash\nsource ros2_ws/install/local_setup.bash\nros2 run ros1_bridge dynamic_bridge\n\n\n\n\n\nStep 6. \n[In terminal 6]\n Launch ROS1 Rviz\n\n\n# terminal 6\nsource /opt/ros/kinetic/setup.bash\nroslaunch turtlebot_rviz_launchers view_robot.launch\n\nwithin rviz gui, click \"Add\", and select \"MarkerArray\", then input \"/object_map/Markers\" into \"Marker Topic\"\n\n\n\n\n3 Interfaces\n\n\n3.1 Topic\n\n\n\n\n/object_map/Markers\n : Publish MarkerArray on RVIZ\n\n\n/object_map/map_save\n : Subscribe map_save topic to save object maps\n\n\n/movidius_ncs_stream/detected_objects\n: Subscribe ObjectsInBoxes from object_analytics\n\n\n/object_analytics/tracking\n: Subscribe TrackedObjects from object_analytics\n\n\n/object_analytics/localization\n: Subscribe ObjectsInBoxes3D from object_analytics\n\n\n\n\n3.2 Save object map\n\n\nros2 topic pub --once /object_map/map_save std_msgs/Int32 -1\n\n\n\n\n\n4 Known Issues\n\n\n* Map tag cannot be correctly displayed in Rviz while robot is moving\n\n\nreason: tf2 python api is not supported in ROS2 currrently\n\n\nnext step: will implement it while tf2-python api is ready in ROS2  \n\n\n* Configure File is not supported\n\n\nreason: yaml configure file and dynamic configure file are not supported in ROS2 currently\n\n\nnext step: will implement it while it is ready in next release of ROS2\n\n\n5 TODO\n\n\n--\n\n\nros2_moving_object\n\n\n1. Overview\n\n\nMoving Object component is addressing moving objects based on messages generated by\nObject Analytics \nros2_object_analytics\n.\nros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding \nmotion information\n, i.e., the \nvelocity\n information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance.\n\n\nThanks to \nros2_object_analytics\n and \nros2_intel_movidius_ncs\n to provide an AI solution for object detection, tracking and localization. See \nthe umbrella wiki page\n to learn the hierarchical data flow and overview description for the related components.\n\n\nThis component involves 2 ROS2 packages:\n- \nmoving_object\n: the main package covering logic of moving object analysis and information generation.\n- \nmoving_object_msgs\n: the message package storing the motion information of moving objects and published into ROS2 system.\n\n\n2. Running the demo\n\n\n#### Step 1. \n[In terminal 1]\n Launch realsense camera node.\n\n\nsource </ros2/install/dir>/local_setup.bash\nsource </my/overlay_ws/dir>/install/local_setup.bash\nrealsense_ros2_camera\n\n\n\n\nStep 2. \n[In terminal 2]\n Launch object analysis node.\n\n\nsource </ros2/install/dir>/local_setup.bash\nsource </my/overlay_ws/dir>/install/local_setup.bash\necho -e \"param_file: alexnet.yaml\\ninput_topic: /object_analytics/rgb > src/ros2_intel_movidius_ncs/movidius_ncs_launch/config/default.yaml\"\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py\n\n\n\n\nStep 3. \n[In terminal 3]\n Launch moving object node.\n\n\nsource </ros2/install/dir>/local_setup.bash\nsource </my/overlay_ws/dir>/install/local_setup.bash\nros2 run moving_object moving_object\n\n\n\n\n3. Interfaces\n\n\nros2_moving_object package publishes some messages to indicate different status/data.\n - \n/moving_object/moving_objects\n merges info from the 3 input messages into one message and calculating (on demand) the velocity info of the tracked moving objects.\n\n\n4. Known issues\n\n\n--\n\n\n5. TODO\n\n\n--",
            "title": "Instruction"
        },
        {
            "location": "/package_instruction/#quick-start",
            "text": "NOTE: All projects are depend on Intel Reanlsense cameras. If use other RGBD sensers, you may need to modify the source code according to instructions as follows.",
            "title": "Quick Start"
        },
        {
            "location": "/package_instruction/#ros2_intel_realsense",
            "text": "1 Overview  These are packages for using Intel RealSense cameras (D400 series) with ROS2.  2 Running the demo  2.1 Start the camera node  To start the camera node in ROS2, plug in the camera, then type the following command:  # To launch with \"ros2 run\"\n$ ros2 run realsense_ros2_camera realsense_ros2_camera\n# OR, to invoke the executable directly\n$ realsense_ros2_camera  This will stream all camera sensors and publish on the appropriate ROS2 topics. PointCloud2 is enabled by default, till we provide ROS2 python launch options.  2.2 View camera data  To start the camera node in ROS2 and view the depth pointcloud in rviz via  ros1_bridge :  # firstly self-build ros1_bridge, than refer to section \"Example 1b: ROS 2 talker and ROS 1 listener\"\n\n# in console #1 launch roscore\n$ source /opt/ros/kinetic/setup.bash\n$ roscore\n\n# in console #2 launch ros1_bridge\n$ source /opt/ros/kinetic/setup.bash\n$ cd ~/ros2_ws\n$ source ./install/local_setup.bash\n$ export ROS_MASTER_URI=http://localhost:11311\n$ ros2 run ros1_bridge dynamic_bridge\n\n# in console #3 launch rviz\n$ source /opt/ros/kinetic/setup.bash\n$ rosrun rviz rviz -d ~/ros2_ws/src/ros2_intel_realsense/realsense_ros2_camera/rviz/ros2.rviz\n\n# in console #4 launch realsense_ros2_camera\n$ source ~/ros2_ws/install/local_setup.bash\n$ realsense_ros2_camera  This will launch  RViz  and display the five streams: color, depth, infra1, infra2, pointcloud.  NOTE:  In case PointCloud2 stream is not observed, try stop the \"realsense_ros2_camera\" and re-launch this node from console #4. This's a known issue and workaround is made (right fixing in ros1_bridge, details discussed in  ROS discourse ).  NOTE:  Visulization in ROS2 pending on  rviz2 .   3 Interfaces  /camera/depth/image_rect_raw  /camera/color/image_raw  /camera/infra1/image_rect_raw  /camera/infra2/image_rect_raw  /camera/depth/color/points  4 Known Issues   This ROS2 node does not currently provide any dynamic reconfigure support for camera properties/presets.  We support Ubuntu Linux Xenial Xerus 16.04 on 64-bit, but not support Mac OS X 10.12 (Sierra) and Windows 10 yet.   5 TODO  A few features to be ported from the latest realsense_ros_camera v2.0.2    RGB-D point cloud (depth_registered)    Preset/Controls",
            "title": "ros2_intel_realsense"
        },
        {
            "location": "/package_instruction/#ros2_intel_movidius_ncs",
            "text": "1 Overview  The Movidius\u2122 Neural Compute Stick ( NCS ) is a tiny fanless deep learning device that you can use to learn AI programming at the edge. NCS is powered by the same low power high performance Movidius\u2122 Vision Processing Unit ( VPU ) that can be found in millions of smart security cameras, gesture controlled drones, industrial machine vision equipment, and more.    This project is a ROS2 wrapper for NC API of  NCSDK , providing the following features:    A ROS2 service for object classification and detection of a static image file    A ROS2 publisher for object classification and detection of a video stream from a RGB camera    Demo applications to show the capabilities of ROS2 service and publisher    Support multiple CNN models of Caffe and Tensorflow    2 Running the Demo  2.1 Classification  2.1.1 Supported CNN Models  #  Table1     CNN Model  Framework  Usage      AlexNet  Caffe  Image / Video    GoogLeNet  Caffe  Image / Video    SqueezeNet  Caffe  Image / Video    Inception_v1  Tensorflow  Image / Video    Inception_v2  Tensorflow  Image / Video    Inception_v3  Tensorflow  Image / Video    Inception_v4  Tensorflow  Image / Video    MobileNet  Tensorflow  Image / Video     2.1.2 Classification Result with GoogLeNet   2.1.3 Running the Demo   Static Image  Video Streaming   2.2 Detection  2.2.1 Supported CNN Models     CNN Model  Framework  Usage      MobileNetSSD(Recommended)  Caffe  Image / Video    TinyYolo_v1  Caffe  Image / Video     2.2.2 Detection Result with MobileNetSSD   2.2.3 Running the Demo   Static Image  Video Streaming   3 Interfaces  3.1 Topic  Classification:  /movidius_ncs_nodelet/classified_objects \nDetection:  /movidius_ncs_nodelet/detected_objects  3.2 Service  Classification:  /movidius_ncs_image/classify_object \nDetection:  /movidius_ncs_image/detect_object  4 Known Issues   Only absolute path of image file supported in image inference demo  Only test on RealSense D400 series camera   5 TODO   Keep synchronized with  ROS NCS Package",
            "title": "ros2_intel_movidius_ncs"
        },
        {
            "location": "/package_instruction/#ros2_object_analytic",
            "text": "1 Overview  Object Analytics (OA) is ROS2 wrapper for realtime object detection, localization and tracking.\nThese packages aim to provide real-time object analyses over RGB-D camera inputs, enabling ROS developer to easily create amazing robotics advanced features, like intelligent collision avoidance and semantic SLAM. It consumes  sensor_msgs::PointClould2  data delivered by RGB-D camera, publishing topics on  object detection ,  object tracking , and  object localization  in 3D camera coordination system.  OA keeps integrating with various \"state-of-the-art\" algorithms.   Object detection offload to VPU, Intel Movidius NCS, with MobileNet SSD model and Caffe framework.   2 Running the demo  Step 1.  [In terminal 1]  Launch Realsense camera node  # Terminal 1:\n. <install-space-with-realsense-ros2-camera>/local_setup.bash\nrealsense_ros2_camera  Step 2.  [In terminal 1]  Launch NCS and OA node  # Terminal 2\n. <install-space-with-object-analytics-launch>/local_setup.bash\necho -e \"param_file: mobilenetssd.yaml\\ninput_topic: /object_analytics/rgb\" > `ros2 pkg prefix movidius_ncs_launch`/share/movidius_ncs_launch/config/default.yaml\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py  Step 3.  [In terminal 1]  Launch OA Rviz  # Terminal 3\n. <install-space-with-object-analytics-launch>/local_setup.bash\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/object_rviz.py  3 Interfaces  3.1 Subscribed topics  /movidius_ncs_stream/detected_objects ( object_msgs::msg::ObjectsInBoxes )  3.2 Published topics  /object_analytics/rgb ( sensor_msgs::msg::Image )  /object_analytics/pointcloud ( sensor_msgs::msg::PointCloud2 )  /object_analytics/localization ( object_analytics_msgs::msg::ObjectsInBoxes3D )  /object_analytics/tracking ( object_analytics_msgs::msg::TrackedObjects )  3.3 Customize launch  By default, object analytics will launch both tracking and localization features, but either tracking or localization or both can be dropped. Detailed please refer comments embedded in launch file.  4 Known issues  --  5 TODO  --",
            "title": "ros2_object_analytic"
        },
        {
            "location": "/package_instruction/#ros2_object_map",
            "text": "1 Introduction  ros2_object_map is ROS2 package which designes to mark tag of objects on map when SLAM. It uses  ros2_object_analytics  for object detection.   2 Running the demo  Step 1.  [In terminal 1]  Launch Realsense Camera node  # terminal 1 \nsource ~/ros2_ws/install/local_setup.bash\nrealsense_ros2_camera  Step 2.  [In terminal 2]  Launch object_analytics node  # terminal 2\nsource ~/ros2_ws/install/local_setup.bash\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py  Step 3.  [In terminal 3]  Launch ros2_object_map node  # terminal 3\nsource source ~/ros2_ws/install/local_setup.bash\nros2 run object_map object_map_node  Step 4.  [In terminal 4]  Launch ROS1 roscore  # terminal 4\nsource /opt/ros/kinetic/setup.bash\nroscore  Step 5.  [In terminal 5]  Launch ROS1 bridge  # terminal 5\nsource /opt/ros/kinetic/setup.bash\nsource ros2_ws/install/local_setup.bash\nros2 run ros1_bridge dynamic_bridge  Step 6.  [In terminal 6]  Launch ROS1 Rviz  # terminal 6\nsource /opt/ros/kinetic/setup.bash\nroslaunch turtlebot_rviz_launchers view_robot.launch\n\nwithin rviz gui, click \"Add\", and select \"MarkerArray\", then input \"/object_map/Markers\" into \"Marker Topic\"  3 Interfaces  3.1 Topic   /object_map/Markers  : Publish MarkerArray on RVIZ  /object_map/map_save  : Subscribe map_save topic to save object maps  /movidius_ncs_stream/detected_objects : Subscribe ObjectsInBoxes from object_analytics  /object_analytics/tracking : Subscribe TrackedObjects from object_analytics  /object_analytics/localization : Subscribe ObjectsInBoxes3D from object_analytics   3.2 Save object map  ros2 topic pub --once /object_map/map_save std_msgs/Int32 -1  4 Known Issues  * Map tag cannot be correctly displayed in Rviz while robot is moving  reason: tf2 python api is not supported in ROS2 currrently  next step: will implement it while tf2-python api is ready in ROS2    * Configure File is not supported  reason: yaml configure file and dynamic configure file are not supported in ROS2 currently  next step: will implement it while it is ready in next release of ROS2  5 TODO  --",
            "title": "ros2_object_map"
        },
        {
            "location": "/package_instruction/#ros2_moving_object",
            "text": "1. Overview  Moving Object component is addressing moving objects based on messages generated by\nObject Analytics  ros2_object_analytics .\nros2_moving_object delivers further analysis for the localized and tracked objects from Object Analytics by adding  motion information , i.e., the  velocity  information about tracked objects. Such information can extend robot's ability of motion planing and collision avoidance.  Thanks to  ros2_object_analytics  and  ros2_intel_movidius_ncs  to provide an AI solution for object detection, tracking and localization. See  the umbrella wiki page  to learn the hierarchical data flow and overview description for the related components.  This component involves 2 ROS2 packages:\n-  moving_object : the main package covering logic of moving object analysis and information generation.\n-  moving_object_msgs : the message package storing the motion information of moving objects and published into ROS2 system.  2. Running the demo  #### Step 1.  [In terminal 1]  Launch realsense camera node.  source </ros2/install/dir>/local_setup.bash\nsource </my/overlay_ws/dir>/install/local_setup.bash\nrealsense_ros2_camera  Step 2.  [In terminal 2]  Launch object analysis node.  source </ros2/install/dir>/local_setup.bash\nsource </my/overlay_ws/dir>/install/local_setup.bash\necho -e \"param_file: alexnet.yaml\\ninput_topic: /object_analytics/rgb > src/ros2_intel_movidius_ncs/movidius_ncs_launch/config/default.yaml\"\nlaunch `ros2 pkg prefix object_analytics_launch`/share/object_analytics_launch/launch/analytics_movidius_ncs.py  Step 3.  [In terminal 3]  Launch moving object node.  source </ros2/install/dir>/local_setup.bash\nsource </my/overlay_ws/dir>/install/local_setup.bash\nros2 run moving_object moving_object  3. Interfaces  ros2_moving_object package publishes some messages to indicate different status/data.\n -  /moving_object/moving_objects  merges info from the 3 input messages into one message and calculating (on demand) the velocity info of the tracked moving objects.  4. Known issues  --  5. TODO  --",
            "title": "ros2_moving_object"
        },
        {
            "location": "/acknowledegment/",
            "text": "Acknowledegment\n\n\nIntel ROS2 Project was contributed by Intel OTC Robotics PRC:\n\n\n\n\n\n\nYang, Harold [harold.yang@intel.com]\n\n\n\n\n\n\nGao, Ethan [ethan.gao@intel.com]\n\n\n\n\n\n\nHuang, Xiaojun [xiaojun.huang@intel.com]\n\n\n\n\n\n\nLi, Chao [chao1.li@intel.com]\n\n\n\n\n\n\nLiu, Sharron [sharron.liu@intel.com]\n\n\n\n\n\n\nLiu, Weizhi [wei.zhi.liu@intel.com]\n\n\n\n\n\n\nShen, Cathy [cathy.shen@intel.com]\n\n\n\n\n\n\nYan, Yu [yu.yan@intel.com]\n\n\n\n\n\n\nYe, Chris [chris.ye@intel.com]\n\n\n\n\n\n\nGuo, Tonny [tony.guo@intel.com]\n\n\n\n\n\n\nLiu, Shenghui [shenghui.liu@intel.com]",
            "title": "Acknowledgement"
        },
        {
            "location": "/acknowledegment/#acknowledegment",
            "text": "Intel ROS2 Project was contributed by Intel OTC Robotics PRC:    Yang, Harold [harold.yang@intel.com]    Gao, Ethan [ethan.gao@intel.com]    Huang, Xiaojun [xiaojun.huang@intel.com]    Li, Chao [chao1.li@intel.com]    Liu, Sharron [sharron.liu@intel.com]    Liu, Weizhi [wei.zhi.liu@intel.com]    Shen, Cathy [cathy.shen@intel.com]    Yan, Yu [yu.yan@intel.com]    Ye, Chris [chris.ye@intel.com]    Guo, Tonny [tony.guo@intel.com]    Liu, Shenghui [shenghui.liu@intel.com]",
            "title": "Acknowledegment"
        }
    ]
}